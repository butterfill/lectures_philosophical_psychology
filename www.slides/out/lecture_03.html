
<!-- - scripts.add(["/vendor/deck.js/deck.core.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.menu.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.hash.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.notes.js"])-->
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:svg="http://www.w3.org/2000/svg">
  <head>
    <!-- (c) copyright 2013 Stephen A. Butterfill-->
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <title>Lecture 03: On the Motor Theory of Speech Perception | Philosophical Psychology</title>
    <meta name="description" content="Slides for a lecture by s.butterfill@warwick.ac.uk"/>
    <meta name="keywords" content="philosophy, psychology, action, joint action, metarepresentation, perception"/>
    <meta name="author" content=""/><meta name="generator" content="DocPad v6.78.4" />
    <meta name="viewport" content="width=device-width"/>
    <!-- - fonts-->
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,900,400italic" rel="stylesheet" type="text/css"/>
    <link href="https://fonts.googleapis.com/css?family=The+Girl+Next+Door" rel="stylesheet" type="text/css"/>
    <!--if lt IE 9
    script(async src="https://html5shim.googlecode.com/svn/trunk/html5.js")
    
    --><style >html.wait {
	cursor: wait !important;
	opacity: 0;
	transition: opacity 0.5s ease;
}</style><link  rel="stylesheet" href="/vendor/boilerplate.min.css" /><link  rel="stylesheet" href="/vendor/normalize.min.css" /><link  rel="stylesheet" href="/vendor/deck.js/deck.all.min.css" /><link  rel="stylesheet" href="/vendor/960_12_col_custom.min.css" /><link  rel="stylesheet" href="/styles/steve_deck_style.css" /><link  rel="stylesheet" href="/vendor/questionmark.js/question.mark.css" />
  </head>
  <body><script >(function(){
	/* Did we just livereload? */
var log = !!(localStorage && console && console.log && true);
if ( log && localStorage.getItem('/docpad-livereload/reloaded') === 'yes' ) {
	localStorage.removeItem('/docpad-livereload/reloaded');
	console.log('LiveReload completed at', new Date())
}

/* Listen for the regenerated event and perform a reload of the page when the event occurs */
var listen = function(){
	var primus = new Primus('/docpad-livereload');
	primus.on('data', function(data){
		if ( data && data.message ) {
			if ( data.message === 'generateBefore' ) {
				if ( log ) {
					console.log('LiveReload started at', new Date());
				}
				if ( typeof document.getElementsByTagName !== 'undefined' ) {
	document.getElementsByTagName('html')[0].className += ' wait';
}
			}
			else if ( data.message === 'generateAfter' ) {
				if ( log ) {
					localStorage.setItem('/docpad-livereload/reloaded', 'yes');
				}
				document.location.reload();
			}
		}
	});
};
	/* Inject socket into our page */
var inject = function(){
	var t = document.createElement('script');
	t.type = 'text/javascript';
	t.async = 'async';
	t.src = '/primus/primus.js';
	t.onload = listen;
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(t, s);
};
	if ( typeof Primus !== 'undefined' ) {
		listen();
	} else {
		inject();
	}
})();</script><script defer="defer"  src="/vendor/jquery.min.js"></script><script defer="defer"  src="/vendor/jquery-svgfix.js"></script><script defer="defer"  src="/vendor/jquery.crSplineBkg.js"></script><script defer="defer"  src="/vendor/velocity.min.js"></script><script defer="defer"  src="/vendor/marked.min.js"></script><script defer="defer"  src="/vendor/modernizr.custom.01932.js"></script><script defer="defer"  src="/vendor/deck.js/deck.velocity.js"></script><script defer="defer"  src="/vendor/deck.js/deck.all.min.js"></script><script defer="defer"  src="/vendor/jquery.jsPlumb-1.3.16-all-min.js"></script><script defer="defer"  src="/scripts/script.js"></script><script defer="defer"  src="/vendor/questionmark.js/question.mark.min.js"></script>
    <div id="helpUnderlay" class="help-underlay">
      <div id="helpModal" class="help-modal">
        <h1>Keyboard Shortcuts<kbd class="help-key"><span>?</span></kbd></h1>
        <div id="helpClose" class="help-close">×</div>
        <!-- .help-close-->
        <div id="helpModalContent" class="help-modal-content">
          <div id="helpListWrap" class="help-list-wrap">
            <ul class="help-list">
              <li class="help-key-unit"><kbd class="help-key"><span>→</span></kbd><span class="help-key-def">Next step</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>←</span></kbd><span class="help-key-def">Previous step</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>↓</span></kbd><span class="help-key-def">Skip this slide</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>↑</span></kbd><span class="help-key-def">Previous slide</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>m</span></kbd><span class="help-key-def">Show slide thumbnails</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>n</span></kbd><span class="help-key-def">Show notes</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>h</span></kbd><span class="help-key-def">Show handout latex source</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>N</span></kbd><span class="help-key-def">Show talk notes latex source</span></li>
            </ul>
            <!-- .help-list-->
          </div>
          <!-- .help-list-wrap-->
        </div>
        <!-- .help-modal-content-->
      </div>
      <!-- .help-modal-->
    </div>
    <!-- .help-underlay-->
    
    
    
    <div class="deck-notes">
      <div class="deck-notes-container"></div>
    </div>
    <div class="deck-handout">
      <div class="deck-handout-container"></div>
    </div>
    <div class="deck-container">
      <section id="instructions" class="slide">
        <div class="words">
          <div class="container_12">
            <div class="grid_12">
              <div class="middle">
                <p class="center">Click here and press the right key for the next slide (or swipe left)</p>
              </div>
            </div>
          </div>
        </div>
      </section>
      <section class="slide">
        <!-- .notes You won't believe how many people emailed me to say the slides don't work.-->
        <div class="words">
          <div class="container_12">
            <div class="grid_12">
              <p>also ...</p>
              <p>Press the left key to go backwards (or swipe right)</p>
              <p>Press n to toggle whether notes are shown (or add '?notes' to the url before the #)</p>
              <p>Press m or double tap to slide thumbnails (menu)</p>
              <p>Press ? at any time to show the keyboard shortcuts</p>
            </div>
          </div>
        </div>
      </section>


<!-- param @cls and param @options should be objects-->




<div class="notes notes-header-tex">\title {Philosophical Psychology \\ Lecture 03: On the Motor Theory of Speech Perception}</div>
<div class="notes notes-header-tex">&nbsp;</div>
<div class="notes notes-header-tex">\maketitle</div>
<div id="title-slide" class="slide"><img src="/img/bkg/joint_action01/AAaaDSC_AA_4400.low.JPG" class="bkg"/>
  <div class="spacer">&nbsp;</div>
  <div class="fade-in">
    <div style="position:relative; top:375px" class="title-block">
      <div class="title-container">
        <h1 style="line-height:45pt;" class="title1 fade-in">Lecture 03: On the Motor Theory of Speech Perception</h1>
        <h3 class="email fade-in">s.butterfill@warwick.ac.uk</h3>
      </div>
    </div>
  </div>
  <div class="handout">\def \ititle {Lecture 03: On the Motor Theory of Speech Perception}</div>
  <div class="handout">\begin{center}</div>
  <div class="handout">{\Large</div>
  <div class="handout">\textbf{\ititle}</div>
  <div class="handout">}</div>
  <div class="handout">&nbsp;</div>
  <div class="handout">\iemail %<s.butterfill@warwick.ac.uk></div>
  <div class="handout">\end{center}</div>
</div>
<div class="handout">&nbsp;</div>
<div class="handout">\section{A Question about Experiences of (Speech) Actions}</div>
<div class="notes notes-header-tex">&nbsp;</div>
<div class="notes notes-header-tex">\section{A Question about Experiences of (Speech) Actions}</div>
<div class="notes">What do we experience when we encounter others’ actions?
One hypothesis (the Indirect Hypothesis) says that such experiences are all experiences of bodily
configurations, of joint displacements and of effects characteristic of particular actions.
Another hypothesis (the Direct Hypothesis) says that 
in observing an action we sometimes experience not only bodily configurations and joint displacements
and their sensory effects but also the action as directed to a particular outcome.</div>

<!-- param @cls and param @options should be objects-->




<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">What do we experience when we encounter others’ <span class="speech hide">speech </span><span> actions?</span></p>
          <div class="slide">
            <p class="em-above center">Indirect Hypothesis <span class="direct-h hide">vs Direct Hypothesis</span></p>
            <div class="slide">
              <div data-what=".direct-h" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
            </div>
          </div>
          <div class="slide">
            <div data-what=".speech" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
            <div data-what=".speech" data-cls="transition-04" class="dv dv-addclass"></div>
            <div data-what=".speech" data-cls="bkg-invert" class="dv dv-addclass"></div>
            <div class="notes">I suppose that speech actions are actions, so I will start with those.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section id="categorical_perception_speech" class="slide"><img src="/img/bkg/joint_action01/DSC_AB_6649.low.JPG" class="bkg"/>
  <div class="spacer">&nbsp;</div>
  <div style="position:relative; top:425px" class="title-block">
    <div class="title-container">
      <h2 class="title1">Speech Perception</h2>
    </div>
  </div>
</section>
<div class="handout">&nbsp;</div>
<div class="handout">\section{Speech Perception}</div>
<div class="notes notes-header-tex">&nbsp;</div>
<div class="notes notes-header-tex">\section{Speech Perception}</div>
<div class="notes">***</div>

<!-- param @cls and param @options should be objects-->




<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">articulatory gesture</p>
          <div class="notes">In speaking we produce an overlapping sequence of articulatory gestures, which are motor actions
involving coordinated movements of the lips, tongue, velum and larynx. These gestures are the units
in terms of which we plan utterances (Browman and Goldstein 1992; Goldstein, Fowler, et al. 2003).
          </div>
          <div class="notes">These are the actions I want to focus on first in thinking about
what we experience when we encounter others’ actions.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">Speech and auditory perception involve distinct processes</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/duplex_01.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">A schematic spectrogram for a synthetic sound which is normally perceived as [ra]. The horizontal
axis represents time, the vertical frequency.
        </div>
        <div class="notes">A schematic spectrogram for [la].
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/duplex_02.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">In the middle you see the \emph{base}, i.e. the part of the spectrogram common to [ra] and [la]. This
is played to one ear
        </div>
        <div class="notes">Below you see the transitions, , i.e. the parts of the spectrogram that differ between [ra] and [la].
When played in isolation these sound like a chirp. When played at the same time as the base but in
the other ear, subjects hear a chirp and a [ra] or a [la] depending on which transition is played.
        </div>
        <div class="notes">How do we know that the same stimuli may be processed by different perceptual systems
concurrently—for instance, how do we know that speech and auditory processing are distinct? A
phenomenon called “duplex” perception demonstrates their distinctness occurs in. Artificial
speech-like stimuli for two syllables, [ra] and [la], are generated. The acoustic signals for each
syllable is artificially broken up into two parts, the “base” and “transition” (see Fig. *** below).
The syllables have the same “base” but differ in the “transition”. When the “transition” is played
alone it sounds like a chirp and quite unlike anything we normally hear in speech. Duplex perception
occurs when the base and transition are played together but in separate ears. In this case, subjects
hear both the chirp that they hear when the transition is played in isolated, and the syllable [la]
or [ra]. Which syllable they hear depends on which transition is played, so speech processing must
have combined the base and transition. By contrast, auditory processing must have failed to combine
them because otherwise the chirp would not have been heard. In this case, then, the perception
resulting from the duplex presentation involves simultaneous auditory and speech recognition
processes. This shows that auditory and speech processing are distinct perceptual processes.
        </div>
        <div class="notes">The duplex case is unusual. We can’t normally hear the chirps we make in speaking because speech
processing inhibits this level of auditory processing. But plainly speech is subject to some auditory
processing for we can hear extra-linguistic qualities of speech; some of these provide cues to
emotional state, gender and class. Perception of these extra-linguistic qualities enables us to
distinguish stimuli within a category. As already mentioned, this is a problem for Repp’s operational
definition. Our ability to discriminate stimuli is the product of both categorical speech processing
and non-categorical auditory processing. If we want to get at the essence of categorical perception
it seems there is no alternative but to appeal to particular perceptual processes rather than
behaviours.
        </div>
        <div class="notes">Source: \citep{Liberman:1981xk}</div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide01.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Here are 12 speech-like sounds.
Acoustically each differs from its neighbours no more than any other does.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide02.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">They would be labelled differently
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide03.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">And within a label they are relatively hard to disciminate whereas ...
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide04.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Discriminating acoustically no less similar stimuli that are given
different labels is easier (faster and more accurate).
        </div>
        <div class="notes">This is categorical perception: speed and accuracy maps onto labelling ...
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide06.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Categorical perception of mating calls and perhaps other acoustic signals is widespread in non-human
animals including monkeys, mice and chinchillas (Ehret 1987; Kuhl 1987), and is even found in
cognitively unsophisticated animals such as frogs (Baugh, Akre and Ryan 2008) and crickets
(Wyttenbach, May and Hoy 1996).
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">What are the objects of categorical perception?</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide26.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">the location of the category boundaries changes depending on contextual factors such as the
speaker’s dialect,22 or the rate at which the speaker talks;23 both factors dramatically affect
which sounds are produced.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide27.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">This means that in two different contexts, different stimuli may result in the same perceptions, and
the same stimulus may result in different perceptions.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide23.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide24.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide25.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">co-articulation, the fact that phonic gestures overlap (this is what makes talking fast).
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">What are the objects of categorical perception?</p>
          <div class="notes show em-above">
            <p class="em-around">1. Speech perception is categorical</p>
            <p class="em-around">  2. The category boundaries correspond (imperfectly but robustly) to differences in articulatory gestures</p>
            <p class="em-around">  3.  The best explanation of (2) involves the hypothesis that the objects of speech perception are articulatory gestures</p>
          </div>
          <div class="notes">\emph{Articulatory Gesture:}
In speaking we produce an overlapping sequence of articulatory gestures, which are motor actions
involving coordinated movements of the lips, tongue, velum and larynx. These gestures are the units
in terms of which we plan utterances (Browman and Goldstein 1992; Goldstein, Fowler, et al. 2003).
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p>The objects of speech perception are articulatory gestures.</p>
          <p class="em-above">... Does this entail that we perceptually experience articulatory gestures?</p>
          <div class="slide">
            <p class="em-above">‘Describing [Mary’s experience] as being as of a dodecahedron … is … normally intended to describe its introspectable character’</p>
            <p class="grey-text right">(Martin 1992: 762).</p>
          </div>
          <div class="slide">
            <p class="em-above">Perceptual experiences are reasons for beliefs ...</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">An argument for perceptual experience of articulatory gestures.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide06.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide07.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide08.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide09.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide10.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">The difference in differences ...
        </div>
        <div class="notes">Here is the argument. Consider two sequences of sensory encounters: (a) a sequence of sensory
encounters with two phonetic events that do not differ with respect to category (both are
realisations of /d/, say), and (b) a sequence of sensory encounters with two phonetic events that do
so differ (one is a realisation of /d/ the other of /g/, say).11 Let the events encountered in the
first sequence differ from each other acoustically in the same way and by the same amount as the
events encountered in the second sequence differ from each other. (That it is possible to find two
such pairs of events follows from the fact that we enjoy categorical perception of speech.) The two
sequences are depicted in Fig. 3. Now:
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="hem-around">(1) The second sequence of sensory encounters, (b), differ from each other more in phenomenal character than the first sequence of sensory encounters, (a), differ from each other.</p>
          <p class="hem-around slide">(2) This difference in differences in phenomenal character is a fact in need of explanation.</p>
          <p class="hem-around slide">(3) The difference cannot be fully explained by appeal only to perceptual experiences as of acoustic features of the stimuli.</p>
          <p class="hem-around slide">(4) The difference can be explained in terms of perceptual experiences as of phonetic properties.</p>
          <p class="hem-around slide">(5) There is no better explanation of the difference.</p>
          <div class="notes">The fourth step in this argument, (4), needs some filling in. How would the thesis that categorical
perception of speech is a form of perceptual experience explain the difference in differences in
phenomenal character? If the thesis is true, the first sequence of sensory encounters, (a), involves
two perceptual experiences as of a single phoneme whereas the second sequence of encounters, (b),
involves perceptual experiences as of different phonemes.12 Let us assume (not very controversially)
that perceptual experiences have phenomenal characters and that which phenomenal character a
perceptual experience has depends in part on what it is as of.13 It follows that differences in what
perceptual experiences are as of can explain differences in the phenomenal characters of those
perceptual experiences. In particular, if it is a fact that (b) involves perceptual experiences as
of different things whereas (a) does not, this could explain why the sensory encounters in (b)
differ in phenomenal character in a way that the sensory encounters in (a) do not.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">Recall the question ...
          </div>
          <p class="center">What do we experience when we encounter others’ <span class="speech">speech </span><span> actions?</span></p>
          <p class="em-above center">Indirect Hypothesis vs  <span class="direct-h">Direct Hypothesis</span></p>
          <div class="slide">
            <div data-what=".direct-h" data-cls="transition-04" class="dv dv-addclass"></div>
            <div data-what=".direct-h" data-cls="bkg-invert" class="dv dv-addclass"></div>
          </div>
          <div class="notes">It looks like the Direct Hypothesis wins, or at least that we must reject the 
Indirect Hypothesis.
          </div>
          <div class="notes">There’s just one little problem ...
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="notes handout show">How could the objects of categorical perception of speech be articulatory gestures?</p>
          <div class="notes">The puzzle here is simple.
Categorical perception of speech happens raidly, and goal-directed actions
are complex.  How can something so complex be computed so quickly?
          </div>
          <div class="slide">
            <p class="em-above notes handout show">‘Humans [can] understand speech delivered at a rate of 20 to 30 ... phonemes per second’
            </p>
            <div class="notes handout ctd"> \citep{Devlin:2006qg}</div>
            <p class="right grey-text">Devlin (2006)</p>
            <div class="notes">Before facing this problem directly, I want to think about action more generally ...
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section id="double_life_motor_representation" class="slide"><img src="/img/bkg/joint_action01/DSC_AB_6862.low.JPG" class="bkg"/>
  <div class="spacer">&nbsp;</div>
  <div style="position:relative; top:425px" class="title-block">
    <div class="title-container">
      <h2 class="title1">The Double Life of Motor Representation</h2>
    </div>
  </div>
</section>
<div class="handout">&nbsp;</div>
<div class="handout">\section{The Double Life of Motor Representation}</div>
<div class="notes notes-header-tex">&nbsp;</div>
<div class="notes notes-header-tex">\section{The Double Life of Motor Representation}</div>
<div class="notes">Motor representations live a kind of double life. Although paradigmatically involved in performing
actions, they also occur when merely observing others act and sometimes influence thoughts about the
goals of observed actions. Further, these influences are content-respecting: what you think about an
action sometimes depends in part on how that action is represented motorically in you.</div>

<!-- param @cls and param @options should be objects-->




<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">The Double Life of Motor Representation</p>
          <div class="notes">Suppose you are reaching for, grasping, transporting and then placing a pen. Performing even
relatively simple action sequences like this involves satisfying many constraints that cannot
normally be satisfied by explicit practical reasoning, especially if performance is to be rapid and
fluent. Rather, such performances require motor representations.
These representations are paradigmatically involved in preparing, executing and monitoring actions.%
\footnote{%
See \citet{wolpert:1995internal, miall:1996_forward, jeannerod:1998nbo, zhang:2007_planning}.
Note that motor representations sometimes occur in an agent who has prepared an action and is required (as it turns out) not to perform it: although she has prevented herself from acting, motor representations specifying the action persist, perhaps because they are necessary for monitoring whether prevention has succeeded \citep{bonini:2014_ventral}.
}
But they also live a double life. Motor representations concerning a particular type of action are
involved not only in performing an action of that type but also sometimes in observing one. That is,
if you were to observe Ayesha reach for, grasp, transport and then place a pen, motor representations
would occur in you much like those that would also occur in you if it were you---not Ayesha---who was
doing this.
          </div>
          <div class="notes">Converging evidence for this assertion comes from a variety of methods and measures ...
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/fogassi_2005_fig1B.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Fogassi et al 2005, figure 1B</p>
        <div class="notes">Single cell recordings in nonhuman primates show that, for each of several types of action, there are
populations of neurons that discharge both when an action of this type is performed and when one is
observed \citep{pellegrino:1992_understanding, gallese:1996_action,Fogassi:2005nf}.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/fogassi_2005_fig1C.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Fogassi et al 2005, figure 1B</p>
        <div class="notes">This is the performance data.
        </div>
        <div class="notes">Note that the neurons are firing before the distinctive part of the action has
occured: that is, the peak is between movement onset and the monkey first touching
the object to be grasped.
        </div>
        <div class="notes">Now let’s compare 
performance with observation.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12"><img src="/img/fogassi_2005_fig5.png" style=""/>
        <p class="source">Fogassi et al 2005, figure 5</p>
        <div class="notes">‘(A) Congruence between the visual and the motor response of a mirror neuron. Unit 169 has a stronger
discharge during grasping to eat than during grasping to place, both when the action is executed and
when it is observed. Conventions as in Fig. 1. (B) Population-averaged responses during motor and
visual tasks (12).’
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="handout notes">
            <p>‘word listening produces a phoneme specific activation of speech motor centres’ \citep{Fadiga:2002kl}</p>
            <p class="em-above">‘Phonemes that require in production a strong activation of tongue muscles, automatically produce, when heard, an activation of the listener's motor centres controlling tongue muscles.’ \citep{Fadiga:2002kl}</p>
          </div>
          <p>‘word listening produces a phoneme specific activation of speech motor centres’ </p>
          <div class="slide">
            <p class="em-above">‘Phonemes that require in production a strong activation of tongue muscles, automatically produce, when heard, an activation of the listener's motor centres controlling tongue muscles.’ </p>
            <div class="notes">Good, but this stops short of showing that the motor activations
actually faciliatate speech recognition ...
            </div>
          </div>
          <p class="right grey-text">Fadiga et al (2002)</p>
          <div class="notes">How did they reach these conclusions?
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p>bi<span class="rr">rr</span><span>a / be</span><span class="rr">rr</span><span>o (pseudo-word) / ba</span><span class="ff">ff</span><span>o</span></p>
          <div class="slide">
            <div data-what=".rr" data-cls="transition-04" class="dv dv-addclass"></div>
            <div data-what=".rr" data-cls="bkg-yellow" class="dv dv-addclass"></div>
            <div class="notes">Inovlves tongue</div>
          </div>
          <div class="slide">
            <div data-what=".ff" data-cls="transition-04" class="dv dv-addclass"></div>
            <div data-what=".ff" data-cls="bkg-blue" class="dv dv-addclass"></div>
            <div class="notes">No tongue required</div>
            <div class="notes">Given TMS to motor cortex tp amplify activity.
Prediction: MEP in tongue muscle stronger for ‘rr’ than ‘ff’.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/fadiga_2002_fig2.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Fadiga et al 2002, figure 2</p>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/kilner_2003/Slide1.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Behaviour: interference effects (ovalization)
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/kilner_2003/Slide2.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/kilner_2003/Slide3.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/kilner_2003/Slide4.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/kilner_2003/Slide5.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/kilner_2003/Slide6.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes show">
            <p class="center huge-glow">Puzzle 1</p>
            <p style="margin-top:-3em;" class="center below-huge-glow">What are those motor representations doing here?</p>
          </div>
          <div class="notes">But there is also another puzzle ...
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">Motor representations in observation facilitate anticipation of others’ actions.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/costantini_2002.png" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <p class="source">Costantini et al, 2012</p>
        <div class="notes">‘We recorded proactive eye movements while participants observed an actor grasping small or large
objects. The participants' right hand either freely rested on the table or held with a suitable grip
a large or a small object, respectively. Proactivity of gaze behaviour significantly decreased when
participants observed the actor reaching her target with a grip that was incompatible with respect to
that used by them to hold the object in their own hand.’
        </div>
        <div class="notes">Follow ups: tie hands; TMS (impair)
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">Motor representations in observation facilitate explicit identification of others’ actions.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/casile_giese_fig1.png" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <p class="source">Casile & Giese 2006, figure 1</p>
        <div class="notes">Ability to perform actions: the 180 degree swing is standard walk, whereas
225 and 270 degree swings are not standard but can be trained.
        </div>
        <div class="notes">Visual discrimination task: ‘The visual recognition experiment was based on a forced-choice
paradigm. In each trial, two point-light stimuli consisting of a total of nine dots were presented
successively, at two different positions on the screen ... Participants had to respond whether both
stimuli represented the same gait pattern. Four cycles of each gait pattern were presented, each
cycle lasting for about 1.2 s. The start position within the gait cycle was randomized across
trials.’
        </div>
        <div class="notes">Then training while BLINDFOLDED.
        </div>
        <div class="notes">Then visual recognition task again.
        </div>
        <div class="notes">‘One possible explanation of the observed motor- visual transfer is that the participants might have
picked up the rhythm that characterizes the trained motor pat- tern, but not necessarily the details
of the learned body movement. To rule out this possibility, we performed a control experiment in
which the motor training was replaced by purely visual training.’
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/casile_giese_fig4A.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Casile & Giese 2006, figure 4A</p>
        <div class="notes">Visual performance correlates with motor performance after (but not before) training.
(They also found no correlation with 225 degrees, which was not trained.)
        </div>
        <div class="notes">This effect is perhaps surprising given that your judgement ultimately rests on purely visual
information (this is the point of the lights) whereas nothing could be seen during the training.
        </div>
        <div class="notes">What explains this difference in judgement before and after training?  Training of this kind typically alters the way things are represented motorically \citep{Calvo-Merino:2006ru}.
\label{expertise_affects_motor}
For this reason, the increase in the probability of making accurate judgements about the goals of others' actions is plausibly a consequence of differences in motor representations in the observer.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/pazzaglia_fig1bi.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Pazzaglia et al 2007, figure 1B (part)</p>
        <div class="notes">task: hear sound, identify one of four pictures.
        </div>
        <div class="notes">Twenty-eight left-hemisphere-damaged patients with or without limb and/or buccofacial apraxia and
seven right- hemisphere-damaged patients with no apraxia were asked to match sounds evoking
human-related actions or nonhu- man action sounds with specific visual pictures.
        </div>
        <div class="notes">‘In the novel sound-picture matching test used in this study, each patient was asked to listen to a
sound and then choose from among four pictures the one corresponding to the heard sound. The sounds
used included limb-related action sounds (LRAS), buccofacial-related action sounds (BRAS)
[ten sounds were transitive, i.e., object related (e.g., inflating a balloon) and ten were
intransitive, i.e., non object related (e.g., coughing). ], and non-human action-related sounds
(NHARS) [e.g. sea waves, breaking]’
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/pazzaglia_fig1bii.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Pazzaglia et al 2007, figure 1B (part)</p>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/pazzaglia_2008_S1.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Pazzaglia et al 2007, Appendix S1 (fragment)</p>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/pazzaglia_2008_fig2.png" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <p class="source">Pazzaglia et al 2007, figure 2</p>
        <div class="notes">Beautiful results!
        </div>
        <div class="notes">Key: limb-related action sounds (LRAS), buccofacial-related action sounds (BRAS), and non-
human action-related sounds (NHARS)
        </div>
        <div class="notes">A+ apraxia; AB+ : buccofacial apraxia; AL+ limb apraxia; LBD: left brain damage; RBD: right brain damage
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/dausilio_2009_fig1.png" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <p class="source">D'Ausilio et al (2009, figure 1)</p>
        <div class="notes">‘Double TMS pulses were applied just prior to stimuli presentation to selectively prime the cortical activity specifically in the lip (LipM1) or tongue (TongueM1) area’
\citep[p.~381]{dausilio:2009_motor}
        </div>
        <div class="notes">‘We hypothesized that focal stimulation would facilitate the perception of 
the concordant phonemes ([d] and [t] with TMS to TongueM1), but that 
there would be inhibition of perception of the discordant items 
([b] and [p] in this case). Behavioral effects were measured via reaction 
times (RTs) and error rates.’ \citep[p.~382]{dausilio:2009_motor}
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/dausilio_2009_fig2.png" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <p class="source">D'Ausilio et al (2009, figure 1)</p>
        <div class="notes">‘Effect of TMS on RTs show a double dissociation between stimulation 
site (TongueM1 and LipM1) and discrimination performance between class 
of stimuli (dental and labial). The y axis represents the amount of RT 
change induced by the TMS stimulation. Bars depict SEM. Asterisks 
indicate significance (p < 0.05) at the post-hoc (Newman-Keuls) comparison.’ 
\citep{dausilio:2009_motor}
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes show">
            <p class="huge-glow">Puzzle 1</p>
            <p style="margin-top:-3em;" class="below-huge-glow">What are those motor representations doing here?</p>
            <div class="slide">
              <p class="right em-above">Motor representations concerning the goals of observed actions sometimes facilitate the identification of goals.</p>
            </div>
            <div class="slide">
              <p class="center huge-glow">Question</p>
              <p style="margin-top:-3em;" class="center"> How?</p>
            </div>
          </div>
          <div class="notes">Question: How is it that motor representations concerning the goals of observed actions sometimes facilitate identification of goals?</div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">Speech Perception Reprise</p>
          <div class="notes">Recall two facts mentioned in discucssing speech perception ...
          </div>
          <div class="slide">
            <p class="em-above">Speech and auditory perception involve distinct processes.</p>
            <div class="notes">This makes sense given that, as \citet{dausilio:2009_motor} argue,
motor processes facilitate the identification of articulatory gestures.
After all, motor processes and auditory processes are likely distinct.
            </div>
          </div>
          <div class="slide">
            <p class="em-above">The objects of speech perception are articulatory gestures.</p>
            <div class="notes">This also makese sense: given that there’s a link between observing an
articulatory gesture and representing it motorically, it seems that the 
motor representation of the articulatory gesture could be what speech
perception aims at.
            </div>
            <div class="notes">(I’m ignoring a lot of complexity about how, given enough context,
motor impairments can have very little impact on speech perception.
Maybe not all speech perception depends on recovering articulatory gestures,
and maybe there are multiple kinds of process that enable us to comprehend
what someone is saying.)
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">Also recall the question
          </div>
          <p class="notes show">How could the objects of categorical perception of speech be articulatory gestures?</p>
          <div class="notes">The puzzle here is simple.
Categorical perception of speech happens raidly, and goal-directed actions
are complex.  How can something so complex be computed so quickly?
          </div>
          <div class="notes">Put it another way: how is it that the articulatory gesture is identified?
          </div>
          <p class="em-above notes handout show">‘Humans [can] understand speech delivered at a rate of 20 to 30 ... phonemes per second’
          </p>
          <div class="notes handout ctd"> \citep{Devlin:2006qg}</div>
          <p class="right grey-text">Devlin (2006)</p>
          <div class="notes">Nothing we’ve yet covered enables us to answer this question.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section id="teleological_stance" class="slide"><img src="/img/bkg/joint_action01/DSC_AB_7018.JPG" class="bkg"/>
  <div class="spacer">&nbsp;</div>
  <div style="" class="title-block">
    <div class="title-container">
      <h2 class="title1">The Teleological Stance</h2>
    </div>
  </div>
</section>
<div class="handout">&nbsp;</div>
<div class="handout">\section{The Teleological Stance}</div>
<div class="notes notes-header-tex">&nbsp;</div>
<div class="notes notes-header-tex">\section{The Teleological Stance}</div>
<div class="notes">The Teleological Stance (Gergeley and Csibra , 1995) provides a computational
theory of pure goal ascription.
Pure goal ascription is the process of identifying goals to which anothers’
actions are directed independently of any knowledge, or beliefs about,
the intentions or other mental states of an agent.</div>

<!-- param @cls and param @options should be objects-->




<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center huge-glow-180">How?</p>
        </div>
      </div>
    </div>
  </div>
  <div style="position: absolute; top:0; left:0; width:100%; height:100%;">
    <div class="container_12">
      <div class="grid_12 ">
        <div class="words">
          <div class="middle">
            <p class="center">Motor representations concerning the goals of observed actions sometimes facilitate the identification of goals.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">To illustrate that there’s really a question here (How is it that motor representations concerning
the goals of observed actions sometimes influence thoughts about them?), consider this about MT:
          </div>
          <p class="handout notes show">‘it is not clear how these [production-perception] links or MNs [mirror neurons] would solve the
problems of mapping variable acoustics to linguistic representations, which first motivated MT [the
motor theory of speech perception].’
          </p>
          <div class="notes handout ctd">\citep[p.~205]{holt:2014_alluring}</div>
          <p class="right grey-text">Holt and Lotto 2014, p. 205</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">To solve this problem, we need to start with an account of pure goal ascription.
          </div>
          <div class="notes">An account of pure goal ascription is an account of how you could 
in principle infer facts about the goals to which actions are directed from
facts about joint displacements, bodily configurations and their effects 
(e.g. sounds).
Such an account is a computational theory of pure goal ascription.
          </div>
          <p class="huge-glow-60">pure goal ascription</p>
          <p><span class="infer">Infer</span><span> The Goals from The Evidence</span></p>
          <div class="slide">
            <p class="em-above">The Goals: facts which goals particular actions are directed to...</p>
          </div>
          <div class="slide">
            <p class="em-above"> <span class="the-evidence">The Evidence</span><span>: facts about events and states of affairs that could be known without 
knowing which goals any particular actions are directed to, nor any facts
about particular mental states ...</span></p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="slide"><img src="/img/bkg_red.jpg" width="1024px" class="bkg"/>
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">goal != intention</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/ants1.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Some ants harvest plant hair and fungus in order to build traps to capture large insects; 
once captured, many worker ants sting the large insects, transport them and carve them up
\citep{Dejean:2005vb}.
        </div>
        <div class="notes">We can think of the ants’ behaviour as goal-directed 
without also thinking of it as involving intention.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <svg width="665px" height="445px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1">
          <defs>
            <filter id="glow-large" width="3" height="3" x="-.5" y="-.5">
              <feGaussianBlur result="blurOut" in="SourceGraphic" stddeviation="15"></feGaussianBlur>
              <feGaussianBlur result="blurOut2" in="SourceGraphic" stddeviation="10"></feGaussianBlur>
              <feGaussianBlur result="blurOut3" in="SourceGraphic" stddeviation="5"></feGaussianBlur>
              <femerge>
                <femergenode in="blurOut"></femergenode>
                <femergenode in="blurOut2"></femergenode>
                <femergenode in="blurOut3"></femergenode>
                <femergenode in="SourceGraphic"></femergenode>
              </femerge>
            </filter>
            <filter id="glow-small" width="1.5" height="1.5" x="-.25" y="-.25">
              <feGaussianBlur result="blurOut" in="SourceGraphic" stddeviation="4"></feGaussianBlur>
              <feGaussianBlur result="blurOut2" in="SourceGraphic" stddeviation="4"></feGaussianBlur>
              <femerge>
                <femergenode in="blurOut"></femergenode>
                <femergenode in="blurOut2"></femergenode>
                <femergenode in="SourceGraphic"></femergenode>
              </femerge>
            </filter>
            <filter id="dropGlowBlack" width="1.5" height="1.5" x="-.25" y="-.25">
              <fegaussianblur in="SourceAlpha" stdDeviation="10" result="blur"></fegaussianblur>
              <femerge>
                <femergenode in="blur"></femergenode>
                <femergenode in="SourceGraphic"></femergenode>
              </femerge>
            </filter>
            <g id="action-ellipse">
              <ellipse cx="0" cy="0" rx="40" ry="40" fill="#000" stroke="#ffffff" stroke-width="3" pointer-events="none" filter="url(#dropGlowBlack)"></ellipse>
            </g>
            <g id="action-ellipse-neon">
              <ellipse cx="0" cy="0" rx="40" ry="40" fill="none" stroke="#A0A" stroke-width="3" pointer-events="none" filter="url(#glow-large)"></ellipse>
              <ellipse cx="0" cy="0" rx="40" ry="40" fill="none" stroke="#2C75FF" stroke-width="3" pointer-events="none" filter="url(#glow-small)"></ellipse>
              <ellipse cx="0" cy="0" rx="40" ry="40" fill="none" stroke="#ffffff" stroke-width="3" pointer-events="none"></ellipse>
            </g>
          </defs>
          <g transform="translate(0.5,0.5)">
            <g class="action-light">
              <ellipse cx="42" cy="42" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none"></ellipse>
              <g transform="translate(12,27)">
                <switch>
                  <foreignobject pointer-events="all" width="59" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                    <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 59px; white-space: normal; text-align: center;">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">light</font></div>
                    </div>
                  </foreignobject>
                  <text x="30" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                </switch>
              </g>
            </g>
            <g class="action-smoke">
              <ellipse cx="132" cy="402" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none"></ellipse>
              <g transform="translate(91,387)">
                <switch>
                  <foreignobject pointer-events="all" width="81" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                    <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 81px; white-space: normal; text-align: center;">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">smoke</font></div>
                    </div>
                  </foreignobject>
                  <text x="41" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                </switch>
              </g>
            </g>
            <g class="joint-action">
              <rect x="32" y="72" width="140" height="310" rx="21" ry="21" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none" filter="url(#dropGlowBlack)"></rect>
              <g class="neon-rect hide">
                <rect x="32" y="72" width="140" height="310" rx="21" ry="21" fill="none" stroke="#A0A" stroke-width="3" pointer-events="none" filter="url(#glow-large)"></rect>
                <rect x="32" y="72" width="140" height="310" rx="21" ry="21" fill="none" stroke="#2C75FF" stroke-width="3" pointer-events="none" filter="url(#glow-small)"></rect>
              </g>
              <rect x="32" y="72" width="140" height="310" rx="21" ry="21" fill="none" stroke="#ffffff" stroke-width="3" pointer-events="none"></rect>
              <g class="action drop">
                <use xlink:href="#action-ellipse" x="87" y="132"></use>
                <g class="neon-ellipse hide">
                  <use xlink:href="#action-ellipse-neon" x="87" y="132"></use>
                </g>
                <g transform="translate(51,117)">
                  <switch>
                    <foreignobject pointer-events="all" width="61" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 61px; white-space: normal; text-align: center;">
                        <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">open</font></div>
                      </div>
                    </foreignobject>
                    <text x="31" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                  </switch>
                </g>
              </g>
              <g class="action throw">
                <use xlink:href="#action-ellipse" x="82" y="242"></use>
                <g class="neon-ellipse hide">
                  <use xlink:href="#action-ellipse-neon" x="82" y="242"></use>
                </g>
                <g transform="translate(44,227)">
                  <switch>
                    <foreignobject pointer-events="all" width="75" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 75px; white-space: normal; text-align: center;">
                        <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">pour</font></div>
                      </div>
                    </foreignobject>
                    <text x="38" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                  </switch>
                </g>
              </g>
              <g class="action discard">
                <use xlink:href="#action-ellipse" x="112" y="312"></use>
                <g class="neon-ellipse hide">
                  <use xlink:href="#action-ellipse-neon" x="112" y="312"></use>
                </g>
                <g transform="translate(68,297)">
                  <switch>
                    <foreignobject pointer-events="all" width="88" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 88px; white-space: normal; text-align: center;">
                        <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">tilt</font></div>
                      </div>
                    </foreignobject>
                    <text x="44" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                  </switch>
                </g>
              </g>
            </g>
            <g class="outcome amuse hide">
              <ellipse cx="562" cy="92" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none"></ellipse>
              <g transform="translate(521,77)">
                <switch>
                  <foreignobject pointer-events="all" width="81" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                    <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 81px; white-space: normal; text-align: center;">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">soak</font></div>
                    </div>
                  </foreignobject>
                  <text x="41" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                </switch>
              </g>
            </g>
            <g class="outcome scare hide">
              <ellipse cx="562" cy="272" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none"></ellipse>
              <g transform="translate(527,257)">
                <switch>
                  <foreignobject pointer-events="all" width="69" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                    <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 69px; white-space: normal; text-align: center;">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">scare</font></div>
                    </div>
                  </foreignobject>
                  <text x="35" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                </switch>
              </g>
            </g>
            <g class="outcome freakout hide">
              <ellipse cx="522" cy="362" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none"></ellipse>
              <g transform="translate(483,332)">
                <switch>
                  <foreignobject pointer-events="all" width="77" height="62" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                    <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 75px; white-space: normal; text-align: center;">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">freak out</font></div>
                    </div>
                  </foreignobject>
                  <text x="39" y="43" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                </switch>
              </g>
            </g>
            <g class="outcome block hide">
              <g class="block-glow hide">
                <ellipse cx="582" cy="182" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none" filter="url(#glow-large)" class="glow"></ellipse>
                <ellipse cx="582" cy="182" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none" filter="url(#glow-large)" class="glow"></ellipse>
              </g>
              <ellipse cx="582" cy="182" rx="40" ry="40" fill="#000000" stroke="#ffffff" stroke-width="3" pointer-events="none" class="no-glow"></ellipse>
              <g transform="translate(547,167)">
                <switch>
                  <foreignobject pointer-events="all" width="69" height="32" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                    <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; font-family: Lato; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 69px; white-space: normal; text-align: center;">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">fill</font></div>
                    </div>
                  </foreignobject>
                  <text x="35" y="28" fill="#000000" text-anchor="middle" font-size="24px" font-family="Lato">[Not supported by viewer]</text>
                </switch>
              </g>
            </g>
            <g class="explain-collective-directedness hide">
              <g class="the-box">
                <rect x="242" y="262" width="210" height="60" rx="9" ry="9" fill="#ffffff" stroke="#ffffff" stroke-width="3" transform="rotate(-15,347,292)" pointer-events="none"></rect>
                <g transform="translate(252,262)rotate(-15,94.5,30)">
                  <switch>
                    <foreignobject pointer-events="all" width="189" height="62" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; width: 195px; white-space: normal; text-align: center;">
                        <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;" class="invert">intention<span class="mr remove-me hide noinvert"> or motor representation</span><br/><span class="iasmr hide">or ???</span></div>
                      </div>
                    </foreignobject>
                  </switch>
                </g>
              </g>
              <g class="coordinates hide">
                <path d="M 352 262 Q 332 212 307 192 Q 282 172 191.91 190.02" fill="none" stroke="#ffffff" stroke-width="3" stroke-miterlimit="10" pointer-events="none"></path>
                <path d="M 185.29 191.34 L 193.23 185.16 L 191.91 190.02 L 195 193.99 Z" fill="#ffffff" stroke="#ffffff" stroke-width="3" stroke-miterlimit="10" pointer-events="none"></path>
                <g transform="translate(199,155)">
                  <switch>
                    <foreignobject pointer-events="all" width="126" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; overflow: hidden; max-height: 26px; max-width: 156px; width: 126px; white-space: normal; text-align: center;">
                        <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">coordinates</font></div>
                      </div>
                    </foreignobject>
                    <text x="63" y="25" fill="#000000" text-anchor="middle" font-size="24px">[Not supported by viewer]</text>
                  </switch>
                </g>
              </g>
              <g class="represents hide">
                <path d="M 352 262 Q 342 222 392 207 Q 442 192 531.95 183.01" fill="none" stroke="#ffffff" stroke-width="3" stroke-miterlimit="10" pointer-events="none" filter="url(#dropGlowBlack)"></path>
                <path d="M 538.66 182.33 L 530.16 187.71 L 531.95 183.01 L 529.26 178.75 Z" fill="#ffffff" stroke="#ffffff" stroke-width="3" stroke-miterlimit="10" pointer-events="none" filter="url(#dropGlowBlack)"></path>
                <g transform="translate(374,167)rotate(-12,58,12)">
                  <switch>
                    <foreignobject pointer-events="all" width="116" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility">
                      <div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 24px; color: rgb(0, 0, 0); line-height: 1.26; vertical-align: top; overflow: hidden; max-height: 26px; max-width: 156px; width: 116px; white-space: normal; text-align: center;">
                        <div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;"><font color="#ffffff">specifies</font></div>
                      </div>
                    </foreignobject>
                    <text x="58" y="25" fill="#000000" text-anchor="middle" font-size="24px">[Not supported by viewer]</text>
                  </switch>
                </g>
              </g>
            </g>
          </g>
        </svg>
        <div class="notes">As this illustrates, 
some actions involving are purposive in the sense that
        </div>
        <div class="slide">
          <div data-what=".outcome" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">among all their actual and possible consequences,
          </div>
        </div>
        <div class="slide">
          <div data-what=".outcome.block .block-glow" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">there are outcomes to which they are directed
          </div>
        </div>
        <div class="slide">
          <div data-what=".joint-action .neon-rect" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">In such cases we can say that the actions are clearly purposive.
          </div>
        </div>
        <div class="slide">
          <div data-what=".explain-collective-directedness" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">The standard answer to this question involves intention.
          </div>
        </div>
        <div class="slide">
          <div data-what=".represents" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">An intention (1) specifies an outcome,
          </div>
        </div>
        <div class="slide">
          <div data-what=".coordinates" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">(2) coordinates the one or several activities which comprise the action;
          </div>
          <div class="notes">and (3) coordinate these activities in a way that would normally facilitate the outcome’s occurrence.
          </div>
          <div class="notes">What binds particular component actions together into larger purposive actions?  
It is the fact that these actions are all parts of plans involving a single intention.
What singles out an actual or possible outcome as one to which the component 
actions are collectively directed?  It is the fact that this outcome is 
represented by the intention.
          </div>
          <div class="notes">So the intention is what binds component actions together into purposive actions and 
links the action taken as a whole to the outcomes to which they are directed.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_3">
        <p style="border-right:1px grey dashed;padding-right:9px;margin-right:-9px" class="quote notes handout show"><span>‘an action can be explained by a </span><span class="goal-state">goal state</span><span> if, and only if, it is </span><span class="seen-as">seen as </span><span> the </span><span class="most-justifiable"> <span class="most">most</span><span> justifiable action </span></span><span>towards that </span><span class="goal-state">goal state</span><span> that is available within the constraints of reality’</span></p>
        <div class="notes handout ctd">\citep[p.~255]{Csibra:1998cx}</div>
        <p class="quote right grey-text">Csibra & Gergely (1998, 255)</p>
      </div>
      <div class="slide">
        <div data-what=".goal-state" data-cls="transition-04" class="dv dv-addclass"></div>
        <div data-what=".goal-state" data-cls="bkg-invert" class="dv dv-addclass"></div>
        <div class="notes">A goal is an outcome to which an action is directed.
A goal-state is a representation of the outcome in virtue of which
the action is directed to that outcome.
So an intention is a goal state.
By contrast, a goal is not a mental state at all.
In order for this to be about *pure* goal ascription, we need to ignore
the Csibra and Gergely’s odd choice of terminology.
        </div>
      </div>
      <div class="slide">
        <div data-what=".goal-state" data-cls="bkg-invert" class="dv dv-removeclass"></div>
      </div>
      <div class="slide">
        <div data-what=".most-justifiable" data-cls="transition-04" class="dv dv-addclass"></div>
        <div data-what=".most-justifiable" data-cls="bkg-pink" class="dv dv-addclass"></div>
      </div>
      <div class="slide">
        <div class="grid_9">
          <p class="step1 hide">1. action a is directed to some goal;</p>
          <p class="step2 hide"> 2. actions of a’s type are <span class="normally">normally</span><span> means of realising outcomes of G’s type;</span></p>
          <p class="step3 hide">3. no available alternative action is a significantly  <span class="better">better*</span><span> means of realising outcome G;</span></p>
          <p class="step4 hide">4. the occurrence of outcome G is  <span class="desirable">desirable</span><span>;</span></p>
          <p class="step5 hide">5. there is no other outcome, G′, the occurrence of which would be at least comparably desirable and where (2) and (3) both hold of G′ and a</p>
          <p class="step6 hide">Therefore:</p>
          <p class="step7">6. <span class="g">G</span><span>  is a goal to which action </span><span class="a">a</span><span>  is directed.</span></p>
        </div>
        <div class="slide">
          <div data-what=".step7 .g" data-cls="transition-04" class="dv dv-addclass"></div>
          <div data-what=".step7 .g" data-cls="bkg-invert" class="dv dv-addclass"></div>
        </div>
        <div class="slide">
          <div data-what=".step7 .g" data-cls="bkg-invert" class="dv dv-removeclass"></div>
          <div data-what=".step7 .a" data-cls="transition-04" class="dv dv-addclass"></div>
          <div data-what=".step7 .a" data-cls="bkg-invert" class="dv dv-addclass"></div>
        </div>
        <div class="slide">
          <div data-what=".step7 .a" data-cls="bkg-invert" class="dv dv-removeclass"></div>
        </div>
        <div class="slide">
          <div data-what=".step1" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">We start with the assumption that we know the event is an action.
          </div>
        </div>
        <div class="slide">
          <div data-what=".step2" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
        </div>
        <div class="slide">
          <div data-what=".most-justifiable" data-cls="bkg-pink" class="dv dv-removeclass"></div>
          <div data-what=".normally" data-cls="transition-04" class="dv dv-addclass"></div>
          <div data-what=".normally" data-cls="bkg-invert" class="dv dv-addclass"></div>
        </div>
        <div class="slide">
          <div data-what=".seen-as" data-cls="transition-04" class="dv dv-addclass"></div>
          <div data-what=".seen-as" data-cls="bkg-invert" class="dv dv-addclass"></div>
          <div class="notes">Why normally? Because of the ‘seen as’.
          </div>
        </div>
        <div class="slide">
          <div data-what=".normally" data-cls="bkg-invert" class="dv dv-removeclass"></div>
          <div data-what=".seen-as" data-cls="bkg-invert" class="dv dv-removeclass"></div>
        </div>
        <div class="slide">
          <div data-what=".most" data-cls="transition-04" class="dv dv-addclass"></div>
          <div data-what=".most" data-cls="bkg-invert" class="dv dv-addclass"></div>
        </div>
        <div class="slide">
          <div data-what=".step3" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
        </div>
        <div class="slide">
          <div data-what=".most" data-cls="bkg-invert" class="dv dv-removeclass"></div>
        </div>
        <div class="slide">
          <div data-what=".better" data-cls="transition-04" class="dv dv-addclass"></div>
          <div data-what=".better" data-cls="bkg-invert" class="dv dv-addclass"></div>
          <div class="notes">What does it mean to say that one means is better than another?
There are different respects in which one action can be better than another as a means 
to some realising some outcome; for example, one action can require less effort than 
another, or one action be a more reliable way to bring the outcome about than another.
          </div>
          <div class="notes handout">An action of type $a'$ is a \emph{better} means of realising outcome $G$ in a given situation than an action of type $a$ if, for instance, actions of type $a'$ normally involve less effort than actions of type $a$ 
in situations with the salient features of this situation 
and everything else is equal; 
or if, for example, actions of type $a'$ are normally more likely to realise outcome $G$ than actions of type $a$
in situations with the salient features of this situation 
and everything else is equal.
          </div>
        </div>
        <div class="slide">
          <div data-what=".better" data-cls="bkg-invert" class="dv dv-removeclass"></div>
        </div>
        <div class="slide">
          <div data-what=".quote" data-css="{&quot;blur&quot;:&quot;2px&quot;}" data-options="{&quot;duration&quot;:500}" class="dv dv-velocity"></div>
          <div data-what=".step6" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">Any objections?
          </div>
          <div class="notes">I have an objection.
Consider a case in which I perform an action directed to 
the outcome of pouring some hot tea into a mug.
Could this pattern of inference imply that the outcome be the goal of my action?
Only if it also implies that moving my elbow is a goal of my action
as well.
And pouring some liquid. 
And moving air in a certain way.
And ...
          </div>
          <div class="notes">How can we avoid this objection?
          </div>
        </div>
        <div class="slide">
          <div data-what=".step4" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
        </div>
        <div class="slide">
          <div data-what=".desirable" data-cls="transition-04" class="dv dv-addclass"></div>
          <div data-what=".desirable" data-cls="bkg-pink" class="dv dv-addclass"></div>
          <div class="notes">Doesn’t this conflict with the aim of explaining *pure* behaviour reading?
Not if desirable is understood as something objective.
[explain]
          </div>
        </div>
        <div class="slide">
          <div data-what=".desirable" data-cls="bkg-pink" class="dv dv-removeclass"></div>
          <div class="notes">Now we are almost done, I think.
          </div>
        </div>
        <div class="slide">
          <div data-what=".step5" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">We just need to add a clause ensuring that the goal in question is maximally 
desirable; this is an attempt to reduce overgeneration of goals.
          </div>
        </div>
        <div class="slide">
          <div data-what=".quote" data-css="{&quot;blur&quot;:0}" data-options="{&quot;duration&quot;:400}" class="dv dv-velocity"></div>
          <div class="notes">OK, I think this is reasonably true to the quote.
So we’ve understood the claim.
But is it true?
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">pure goal ascription = no mental state ascrptions needed</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div style="z-index:-22;" class="right-half-white"></div>
  <div class="container_12">
    <div class="notes">Why else is this significant?
Partly because pure goal ascription is an important part of social cognition,
so it is good to taste some success in giving a computational theory after our
recent less than successful attempts.
    </div>
    <div class="notes">Also important is the additional structure we have.
    </div>
    <div class="grid_6 words left-half">
      <div style="padding-right:1em;">
        <div class="center">
          <p>Davidson & Dennett</p>
          <p class="em-above">from:</p>
          <p>joint displacements, bodily configurations and their effects</p>
          <p class="em-above">to:</p>
          <p class="em-above">propositional attitudes (belief, desire, ...)</p>
        </div>
      </div>
    </div>
    <div class="grid_6 words invert right-half">
      <div style="padding-left:1em;">
        <div class="center">
          <p>Csibra & Gergely</p>
          <p class="em-above">from:</p>
          <p>joint displacements, bodily configurations and their effects</p>
          <p class="em-above">to:</p>
          <p class="em-above">goal-directed actions</p>
          <p class="em-above">to:</p>
          <p class="em-above">propositional attitudes (belief, desire, ...)</p>
        </div>
      </div>
    </div>
    <div class="notes">Why is adding an extra step significant?
Not only because it provides the beginnings of a missing component 
that Dennett’s and Davidson’s theories each require.
But, more importantly, because it suggests that we can 
broaden the evidential basis for radical interpretation.
    </div>
    <div class="notes">If I am performing an action directed to stripping a nettle, then 
it is likely that I have beliefs, desires and intentions about 
the nettle and this outcome.
So plausibly facts about which goals someone’s actions are directed to
can constrain facts about which objects her beliefs, desires and intentions
are about.
This may help Davidson with the probelm of indeterminacy.
    </div>
    <div class="notes">Recall that, on Davidson’s account, the evidence for radical interpretation
was changes in attitudes towards the truth of particular sentences.
Maybe the evidence should include goal-directed actions, including those
which occur in nonlinguistic and noncommunicative contexts.
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">The thought is that the objects specified by the goals of your actions
are the primary things to which you refer.
          </div>
          <p class="center">Indeterminacy of reference</p>
          <p class="em-above"> </p>
          <table class="data">
            <thead>
              <tr>
                <td></td>
                <td>ordinary</td>
                <td>contrived</td>
              </tr>
            </thead>
            <tbody>
              <tr class="odd">
                <td>names</td>
                <td>‘Beatrice’ refers to Beatrice</td>
                <td>‘Beatrice’ refers to shadow-Beatrice</td>
              </tr>
              <tr class="even">
                <td> <span class="step2">predicates</span></td>
                <td> <span class="step2">‘... is happy’ - is true of happy things</span></td>
                <td> <span class="step2">‘... is happy’ - is true of things that are the shadows of happy things</span></td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p> Phenomenal character ‘stands ready and available to make a direct impact on beliefs’</p>
          <p class="grey-text right">Tye, 1995 pp. 143–4 (see also 103–4)</p>
          <div class="notes">perceptual experiences have phenomenal character where phenomenal character is something which
“stands ready and available to make a direct impact on beliefs” (1995: 143–4, see also 103–4).
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide13.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Infants enjoy categorical perception of speech from around four months of age or earlier.
Prelinguistic infants’ categorical perception is adult-like in the sense that it is subject to
complex effects of speaker and context on where perceptual category boundaries fall (Kuhl 1987:
376–82, 2004: 834). Infants’ categorical perception also plays an important role in language
acquisition (Eimas, Siqueland, et al. 1971; Jusczyk 1995; Saffran, Newport and Aslin 1996).
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide14.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide15.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide16.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide17.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide18.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide19.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide20.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide21.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Consider perceptually-based beliefs involving demonstrative concepts such as the belief that This
phoneme is that phoneme. Children’s and adults’ untrained judgements about phonemes are often
surprisingly inaccurate, and they are typically influenced by acoustic features such as sonority as
well as their knowledge of spelling and linguistic structure (Scarborough, Ehri, et al. 1998;
Treiman and Cassar 1997; Lehtonen and Treiman 2007; Hallé, Chéreau and Segui 2000). In addition,
children tend to systematically misidentify phonemes depending on the context in which they appear
(Treiman 1985: 197). Categorical perception is not similarly affected by these factors (Serniclaes,
Ventura, et al. 2005). This is evidence for the view that whereas categorical perception tracks
articulatory gestures, demonstrative concepts track some sort of hybrid acoustic-
linguistic properties.20 This view is further supported by the fact that untrained subjects
sometimes regard their phonetic beliefs as beliefs about the sounds which make up words (compare
Scarborough, Ehri, et al. 1998: 119–20 on ‘little sounds’).
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p> Phenomenal character ‘stands ready and available to make a direct impact on beliefs’</p>
          <p class="grey-text right">Tye, 1995 pp. 143–4 (see also 103–4)</p>
          <div class="notes">How does this bear on Tye’s claim that perceptual experiences stand “ready and available to make a
direct impact on beliefs”? This claim implies that in good circumstances and where background
conditions are met, the properties subjects enjoy perceptual experiences as of are also properties
they can think about. Suppose categorical perception of speech were a form of perceptual experience.
In that case, subjects would enjoy perceptual experiences as of articulatory gestures (or as of
events or properties matching these in extension). Despite this, they fail to be able to think about
any such properties, for, as we have seen, there is a large and systematic discrepancy between the
boundaries of their perceptual categories and the extensions of the concepts involved in their
judgements, even the simplest perceptually-based demonstrative judgements. All by itself this
discrepancy carries little weight. For Tye’s claim about perceptual experiences making a direct
impact on beliefs must allow for the possibilities of interference and inhibition from false
beliefs. And in the case of categorical perception of speech, there is evidence that both
interference and relevant false beliefs are present. But, crucially, these factors do not fully
explain the extent of the discrepancies between categorical perception and belief (see footnote 20).
Rather it appears that whereas categorical perception tracks one type of thing (articulatory
gestures), demonstrative concepts track something altogether different (little sounds, perhaps). So
if categorical perception of speech did involve perceptual experiences as of acoustic properties,
its existence would be evidence against Tye’s claim that perceptual experiences stand “ready and
available to make a direct impact on beliefs.”
          </div>
          <div class="notes">footnote 20: There are two alternative possible explanations for the discrepancies between
categorical perception and phonetic judgements: subjects may find it difficult to attend to phonetic
properties, and they may find it difficult to inhibit tendencies to make judgements on the basis of
orthography. While both claims may be true (first claim: Treiman 1985: 199–200; second claim:
Scarborough, Ehri, et al. 1998: 138), they do not fully explain the discrepancies.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p style="margin-top:-3em;" class="center huge-glow">Puzzle 2</p>
          <p class="center below-huge-glow">How could motor representations have content-respecting effects on judgements?</p>
          <div class="notes">I want to answer this question in an indirect way,
via the Teleological Stance ...
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section id="phenomenal_expectations" class="slide"><img src="/img/bkg/joint_action01/AAaaDSC_AA_4400.low.JPG" class="bkg"/>
  <div class="spacer">&nbsp;</div>
  <div style="position:relative; top:425px" class="title-block">
    <div class="title-container">
      <h2 class="title1">Phenomenal Expectations</h2>
    </div>
  </div>
</section>
<div class="handout">&nbsp;</div>
<div class="handout">\section{Phenomenal Expectations}</div>
<div class="notes notes-header-tex">&nbsp;</div>
<div class="notes notes-header-tex">\section{Phenomenal Expectations}</div>
<div class="notes">Categorical percpetion of speech is more nearly a form of sensation than of perceptual experience of
articulatory gestures. Maybe.</div>

<!-- param @cls and param @options should be objects-->




<section class="slide"><img src="/img/wire.jpg" width="1024px" class="bkg"/>
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">What is a phenomenal expectation?  Consider a second illustration.
          </div>
          <div class="notes">Here is a wire.
Contrast two sensory encounters with this wire. In the first you visually 
experience the wire as having a certain shape. In the second you receive an 
electric shock from the wire without seeing or touching it.%
\footnote{This illustration is borrowed from Campbell (2002: 133–4); I use it to support a claim weaker than his.}
The first sensory encounter involves perceptual experience as of a property of
the wire whereas, intuitively, the second does not. 
I take this intuition to be correct.%
\footnote{
Notice that the intuition is not that the shock involves no 
perceptual experience at all, only that the shock does not involve 
perceptual experience as of any property of the wire. Notice also that the 
intuition concerns what a perceptual experience is as of, and not directly 
what is represented in perception. The relation between these two is 
arguably not straightforward (compare, e.g., \citet[p.~28]{Shoemaker:1994el} or 
\citet[pp.~50--2]{Chalmers:2006xq} on distinguishing representational from 
phenomenal content).
}
          </div>
          <div class="notes">The intuition is potentially revealing because the electric shock involves 
rich phenomenology, and its particular phenomenal character depends in part 
on properties of its cause (changes in the strength of the electric current 
would have resulted in an encounter with different phenomenal character). 
So there are sensory encounters which, despite having phenomenal characters 
that depend in part on which properties are encountered, are not perceptual 
experiences as of those properties.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/bush-obama.jpg" width="1024px" class="bkg"/>
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">What is a phenomenal expectation?  Consider a third (and final) illustration.
          </div>
          <div class="notes">Here is a face that I hope will seems familiar to most people.
When you see this face, you have a feeling of familiarity.
This feeling of familiarity is not just a matter of belief:
even if you know for sure that you have never encountered the person
depicted here (and trust me, you haven’t), the feeling of familiarity
will persist.
Nor is the feeling a matter of perceptual experience: you can’t 
perceptually experience familiarity
any more than you can perceptually experience electricity.
          </div>
          <div class="notes">(The face is a composite of Bush and Obama.  It is chosen to illustrate that
the feeling of familiarity is not a consequence of how familiar things 
actually are; instead it may be a consequnece of 
the degree of fluency with which unconscious processes can identify 
perceived items \citep{Whittlesea:1993xk,Whittlesea:1998qj}.
Learning a grammar can also generate feelings of familiarity.
Subjects who have implicitly learned an artificial grammar report feelings 
of familiarity when they encounter novel stimuli that are part of 
the learnt grammar \citep{scott:2008_familiarity}.
They are also not doomed to treat feelings of familiarity as being
about actual familiarity:
instead subjects can use feeling of 
familiarity in deciding whether a stimulus is from that grammar 
\citep{Wan:2008_familiarity}.)
          </div>
          <div class="notes">I could go on to mention the feeling you have when someone’s eyes are 
boring into your back, or the feeling that a name is on the tip of your 
tongue.  
But let me focus just on the feelings associated with electricity and 
with familiarity.
These feelings are paradigm cases of phenomenal expectation.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">All three examples (the feelings of magic, of electricity and of 
familiarity) show that:
          </div>
          <p class="pe hide">Phenomenal expectations</p>
          <p class="notes show"><span class="there">There </span><span>are aspects of the overall phenomenal character of experiences </span><span>which their subjects take to be informative about things that are only </span><span>distantly related (if at all) to the things that those experiences </span><span>intentionally relate the subject to. </span></p>
          <div class="notes">To illustrate, having a feeling of familiarity is not a matter of standing 
in any
intentional relation to the property of familiarity, but it is something
that we can interpret as informative about famility.
          </div>
          <div class="slide">
            <div data-what=".there" data-css="{&quot;opacity&quot;:0}" data-options="{&quot;visibility&quot;:&quot;hidden&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
            <div data-what=".pe" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
            <div class="notes">Phenomenal expectations are these aspects of experience.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="step1">
            <p>Phenomenal expecations </p>
            <p>can be thought of as </p>
            <p>sensations.</p>
          </div>
          <div class="notes">Phenomenal expectations can be thought of as sensations in approximately
Reid’s sense.%
\footnote{
\citet{Reid:1785cj,Reid:1785nz}.
Even if you don’t believe that there are sensations in Reid’s sense,
thinking of phenomenal expectations as if they were sensations will
serve to illustrate their characteristic features.
The main points that follow are consistent with several different ways of
thinking about phenomenal expectations.
For instance, you might take the view that 
what I am calling phenomenal expectations are
perceptual experiences of the body or of bodily reactions,
or that they involve some kind of cognitive phenomenology.
The essential claim is just that the phenomenal expectations associated with
the operations of object indexes are not constituted by states which involve
intentional relations to any of the things which are assigned an object index.
}
          </div>
          <div class="slide step2">
            <div data-what=".step1" data-css="{&quot;blur&quot;:&quot;2px&quot;}" data-options="{&quot;duration&quot;:500}" class="dv dv-velocity"></div>
            <p class="em-above">Sensations are </p>
            <ol>
              <li>monadic properties of perceptual experiences</li>
              <li>individuated by their normal causes</li>
              <li>(so they do not involve an <span class="intentional-relation">intentional relation</span><span>)</span></li>
              <li>which alter the overall phenomenal character of those experiences</li>
              <li>in ways not determined by the experiences’ contents.</li>
            </ol>
            <div class="notes">Sensations are:
\begin{enumerate}
\item monadic properties of events, specifically perceptual experiences,  
\item individuated by their normal causes% %{Tye, 1984 #1744@204}
---in the case of feelings of familiarity, its normal cause is ease of processing
\item which alter the overall phenomenal character of those experiences
\item in ways not determined by the experiences’ contents 
(so two perceptual experiences can have the same content while one has a sensational property which the other lacks).
\end{enumerate}
            </div>
          </div>
          <div class="slide">
            <div data-what=".step2" data-css="{&quot;blur&quot;:&quot;2px&quot;}" data-options="{&quot;duration&quot;:500}" class="dv dv-velocity"></div>
            <p class="em-above">Phenomenal expectations trigger beliefs only via associations.</p>
            <div class="notes">An important consequence is that phenomenal expectations can lead to beliefs
only via associations or further beliefs.
They are signs which need to be interpreted by their subjects
(\citealp[Essay~II, Chap.~16, p.~228]{Reid:1785cj}
\citealp[Chap.~VI sect.~III, pp.~164–5]{Reid:1785nz}).
Let me explain.
            </div>
            <div class="notes">As a scientist, you can pick out the feeling of familiarity as that
phenomenal expectation which is normally caused by the degree to which
certain processes are fluent.
But as the subject of who has that phenomenal expectation, you do not 
necessarily know what its typical causes are.
This is something you have to work out in whatever ways you work out
the causes of any other type of event.
            </div>
            <div class="notes">(Contrast phenomenal expectations with perceptual experiences.
Having 
a perceptual experience of, say, a wire’s shape, involves standing
in an intentional relation to the wire’s shape; and the phenomenal
character of this perceptual experience is specified by this 
intentional relation.%
\footnote{
Compare \citet[p.~380]{Martin:2002yx}:
‘I attend to what it is like for me to inspect the lavender bush through 
perceptually attending to the bush itself.’ 
And \citet[p.~211]{byrne:2001_intentionalism}
‘subject can only discover the phenomenal character of her experience by 
attending to the world ... as her experience represents it.’
}
Such perceptual experiences are often held to reveal the wire’s shape to the 
subject and so lead directly to beliefs.%
\footnote{
Compare \citet[p.~222]{Johnston:1992zb}:
‘[j]ustified belief … is available simply on the basis of visual perception’;
\citet[p.~143–4]{Tye:1995oa}:
‘Phenomenal character “stands ready … to make a direct impact on beliefs’;
and
\citet[p.~291]{Smith:2001iz}:
‘[p]erceptual experiences are … intrinsically … belief-inducing.’
})
            </div>
            <div class="notes">(By contrast, having a phenomenal expectation concerning familiarity or an
physical object’s path does not involve standing in any intentional relation
to these things.
The phenomenal expectation is individuated by its normal causes, rather 
than by any intentional relation.
And a phenomenal expectation leads to belief, if at all, only indirectly.
For learning is required in order for the subject to come to a view on
what tends to cause the phenomenal expectation.)
            </div>
            <div class="notes">Phenomenal expectations have been quite widely neglected in philosophy and
developmental psychology.
They are a means by which cognitive processes enable perceivers to 
acquire dispositions to form beliefs about objects’ properties which are 
reliably true.    
Phenomenal expectations provide a low-cost but efficient bridge between 
non-conscious cognitive processes and conscious reasoning.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p>Q1: What are the objects of categorical perception?  Articulatory gestures!</p>
          <p>Q2: Do we perceptually experience articulatory gestures?  Maybe not.</p>
          <p class="em-above">Next: Do motor representations underpin categorical perception of speech?</p>
        </div>
      </div>
    </div>
  </div>
</section>
    </div>
  </body>
</html>