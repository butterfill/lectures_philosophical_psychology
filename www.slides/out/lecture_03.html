<!-- - scripts.add(["/vendor/deck.js/deck.core.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.menu.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.hash.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.notes.js"])--><html xmlns="http://www.w3.org/1999/xhtml" xmlns:svg="http://www.w3.org/2000/svg"><head><!-- (c) copyright 2013 Stephen A. Butterfill--><meta charset="utf-8"/><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><title>Lecture 03: Experience of Action | Philosophical Psychology</title><meta name="description" content="Slides for a lecture by s.butterfill@warwick.ac.uk"/><meta name="keywords" content="philosophy, psychology, action, joint action, metarepresentation, perception"/><meta name="author" content=""/><meta name="generator" content="DocPad v6.78.4" /><meta name="viewport" content="width=device-width"/><!-- - fonts--><link href="https://fonts.googleapis.com/css?family=Lato:300,400,900,400italic" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=The+Girl+Next+Door" rel="stylesheet" type="text/css"/><!--if lt IE 9script(async src="https://html5shim.googlecode.com/svn/trunk/html5.js")
--><link  rel="stylesheet" href="/vendor/boilerplate.min.css" /><link  rel="stylesheet" href="/vendor/normalize.min.css" /><link  rel="stylesheet" href="/vendor/deck.js/deck.all.min.css" /><link  rel="stylesheet" href="/vendor/960_12_col_custom.min.css" /><link  rel="stylesheet" href="/styles/steve_deck_style.css" /><link  rel="stylesheet" href="/vendor/questionmark.js/question.mark.css" /></head><body><script defer="defer"  src="/vendor/jquery.min.js"></script><script defer="defer"  src="/vendor/jquery-svgfix.js"></script><script defer="defer"  src="/vendor/jquery.crSplineBkg.js"></script><script defer="defer"  src="/vendor/velocity.min.js"></script><script defer="defer"  src="/vendor/marked.min.js"></script><script defer="defer"  src="/vendor/modernizr.custom.01932.js"></script><script defer="defer"  src="/vendor/deck.js/deck.velocity.js"></script><script defer="defer"  src="/vendor/deck.js/deck.all.min.js"></script><script defer="defer"  src="/vendor/jquery.jsPlumb-1.3.16-all-min.js"></script><script defer="defer"  src="/scripts/script.js"></script><script defer="defer"  src="/vendor/questionmark.js/question.mark.min.js"></script><div id="helpUnderlay" class="help-underlay"><div id="helpModal" class="help-modal"><h1>Keyboard Shortcuts<kbd class="help-key"><span>?</span></kbd></h1><div id="helpClose" class="help-close">×</div><!-- .help-close--><div id="helpModalContent" class="help-modal-content"><div id="helpListWrap" class="help-list-wrap"><ul class="help-list"><li class="help-key-unit"><kbd class="help-key"><span>→</span></kbd><span class="help-key-def">Next step</span></li><li class="help-key-unit"><kbd class="help-key"><span>←</span></kbd><span class="help-key-def">Previous step</span></li><li class="help-key-unit"><kbd class="help-key"><span>↓</span></kbd><span class="help-key-def">Skip this slide</span></li><li class="help-key-unit"><kbd class="help-key"><span>↑</span></kbd><span class="help-key-def">Previous slide</span></li><li class="help-key-unit"><kbd class="help-key"><span>m</span></kbd><span class="help-key-def">Show slide thumbnails</span></li><li class="help-key-unit"><kbd class="help-key"><span>n</span></kbd><span class="help-key-def">Show notes</span></li><li class="help-key-unit"><kbd class="help-key"><span>h</span></kbd><span class="help-key-def">Show handout latex source</span></li><li class="help-key-unit"><kbd class="help-key"><span>N</span></kbd><span class="help-key-def">Show talk notes latex source</span></li></ul><!-- .help-list--></div><!-- .help-list-wrap--></div><!-- .help-modal-content--></div><!-- .help-modal--></div><!-- .help-underlay-->


<div class="deck-notes"><div class="deck-notes-container"></div></div><div class="deck-handout"><div class="deck-handout-container"></div></div><div class="deck-container"><section id="instructions" class="slide"><div class="words"><div class="container_12"><div class="grid_12"><div class="middle"><p class="center">Click here and press the right key for the next slide (or swipe left)</p></div></div></div></div></section><section class="slide"><!-- .notes You won't believe how many people emailed me to say the slides don't work.--><div class="words"><div class="container_12"><div class="grid_12"><p>also ...</p><p>Press the left key to go backwards (or swipe right)</p><p>Press n to toggle whether notes are shown (or add '?notes' to the url before the #)</p><p>Press m or double tap to slide thumbnails (menu)</p><p>Press ? at any time to show the keyboard shortcuts</p></div></div></div></section>

<!-- param @cls and param @options should be objects-->



<div class="notes notes-header-tex">\title {Philosophical Psychology \\ Lecture 03: Experience of Action}</div><div class="notes notes-header-tex">&nbsp;</div><div class="notes notes-header-tex">\maketitle</div><div id="title-slide" class="slide"><img src="/img/bkg/flowers/AADSC_AA_7442.JPG" class="bkg"/><div class="spacer">&nbsp;</div><div class="no-fade-in"><div style="" class="title-block"><div class="title-container"><h1 style="line-height:45pt;" class="title1 no-fade-in"> <span class="word_0">Lecture </span><span class="word_1">03: </span><span class="word_2">Experience </span><span class="word_3">of </span><span class="word_4">Action </span></h1><h3 class="email no-fade-in">s.butterfill@warwick.ac.uk</h3></div></div></div><div class="handout">\def \ititle {Lecture 03: Experience of Action}</div><div class="handout">\begin{center}</div><div class="handout">{\Large</div><div class="handout">\textbf{\ititle}</div><div class="handout">}</div><div class="handout">&nbsp;</div><div class="handout">\iemail %<s.butterfill@warwick.ac.uk></div><div class="handout">\end{center}</div><div class="notes">I want to start by recalling some issues from the first two lectures.
Today I will attempt to tie these together, then, next week, we will move
on to a different set of issues.
(Perhaps colour?)</div></div><div class="handout">&nbsp;</div><div class="handout">\section{The Interface Problem (Recap)}</div><div class="notes notes-header-tex">&nbsp;</div><div class="notes notes-header-tex">\section{The Interface Problem (Recap)}</div><div class="notes">Some actions involve both intention and motor representation.
Sometimes, in acting, intentions and motor representations 
specify outcomes which nonaccidentally match.
How are such non-accidental matches possible?</div>
<!-- param @cls and param @options should be objects-->



<div class="handout">The interface problem: explain how intentions and motor representations, with their distinct
representational formats, are related in such a way that, in at least some cases, the outcomes they
specify non-accidentally match.</div><div class="handout">‘both mundane cases of action slips and pathological conditions, such as apraxia or anarchic hand
syndrome (AHS), illustrate the existence of an interface problem’ 
\citep[p.~7]{mylopoulos:2016_intentions}.</div><div class="handout">Two collections of outcomes, A and B, \emph{match} in a particular context just if, in that context,
either the occurrence of the A-outcomes would normally constitute or cause, at least partially, the
occurrence of the B-outcomes or vice versa. To illustrate, one way of matching is for the B-outcomes
to be the A-outcomes. Another way of matching is for the B-outcomes to stand to the A-outcomes as
elements of a more detailed plan stand to those of a less detailed one.</div><section class="slide"><div style="z-index:-22;" class="right-half-white hide"></div><div class="container_12"><div class="clear"></div><div class="words run-across"> <p class="center problem">The Interface Problem:</p><p class="center"><span class="qq hide">How are non-accidental matches possible?</span></p></div><div class="container_12"></div><div class="grid_6 words left-half"><div style="padding-right:1em;"><p>Motor representations specify goals.</p><div class="notes">Motor representations specify goals.</div><p class="slide em-above">Intentions specify goals.<div class="notes">And of course, so do intentions.</div></p><p class="slide em-above">Some actions involve both intention and motor representation.<div class="notes">Further, many actions involve both intention and motor representation.
When, for example, you form an intention to turn the lights out, the goal
of flipping the light switch may be represented motorically in you.</div><div class="notes">The nonaccidental success of our actions therefore depends on the outcomes
specified by our intentions and motor representations matching.</div></p><p class="inf-int hide em-above">Intention and motor representation are not inferentially integrated<span class="format hide"> (because representational format?).</span></p></div></div><div class="grid_6 words invert right-half hide"><div style="padding-left:1em;"><div class="slide"><div data-what=".right-half-white, .right-half" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div><p>Two  outcomes, A and B, match in a particular context just if, in that context, 
either the occurrence of A would normally constitute or cause, at least 
partially, the occurrence of B or vice versa.</p><div class="notes">But how should they match?
I think they should match in this sense:
the occurrence of the outcome specified by the motor representation would 
would normally constitute or cause, at least 
partially, the occurrence of the outcome specified by the intention.</div></div></div></div><div class="slide"><div data-what=".qq" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div><div class="notes">Now we have to ask, How are nonaccidental matches possible?
If you asked a similar question about desire and intention, the answer would be 
straightforward: desire and intention are integrated in practical reasoning, so it 
is no surprise that what you intend sometimes nonaccidentally conforms to what you intend.
But we cannot give the same sort of answer in the case of motor representations and 
intentions because ...</div></div><div class="slide"><div data-what=".inf-int" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div><div class="notes">Intention and motor representation are not inferentially integrated.</div><div class="notes">Beliefs, desires and intentions are related to the premises and conclusions
in practical reasoning.  Motor representations are not.
Similarly, intentions do not feature in motor processes.</div></div><div class="slide"><div data-what=".format" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div><div class="notes">Failure of inferential integration follows from the claim that they differ in 
format and are not translated. But I suspect that more people will agree that there is a
lack of inferential integration than that they differ in representational format.
(must illustrate format with maps).</div></div><div class="slide"><div data-what=".qq" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".qq" data-cls="bkg-pink" class="dv dv-addclass"></div><div class="notes">So this is the Interface Problem: how do the outcomes specified by intentions and 
motor representations ever nonaccidentally match?</div></div><div class="slide"><div data-what=".left-half, .right-half, .run-across" data-css="{&quot;blur&quot;:&quot;5px&quot;}" data-options="{&quot;duration&quot;:500}" class="dv dv-velocity"></div><div style="position: absolute; top:0; left:0; width:100%; height:100%;"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"> <div id="timer1" class="timer-outer"><div class="timer center timer-120s "><div class="mask"></div></div><div class="timer-120s-block-wrapper"><div class="timer-120s-block"><p class="center"> <span>How do the outcomes specified by</span><br/><span>intentions & </span><span>motor representations </span><br/><span>ever nonaccidentally match?</span></p></div></div></div><div class="slide"><div data-what="#timer1 .timer.hide" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:0}" class="dv dv-velocity"></div><div data-what="#timer1 .timer" data-cls="running" class="dv dv-addclass"></div></div></div></div></div></div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><p class="center">from lecture 2 ...</p></div></div></div></div></section><div class="handout">&nbsp;</div><div class="handout">\section{The Motor Theory of Goal Tracking (recap)}</div><div class="notes notes-header-tex">&nbsp;</div><div class="notes notes-header-tex">\section{The Motor Theory of Goal Tracking (recap)}</div><div class="notes">How do humas track the goals of others’ actions?
According to the Motor Theory of Goal Tracking, it is sometimes* by 
means of motor processes.
More carefully, the Motor Theory of Goal Tracking consists of these claims: 
(1) in action observation, possible outcomes of observed actions are represented motorically;
(2) these representations trigger motor processes much as if the observer were performing actions
directed to the outcomes;
(3) such processes generates predictions;
(4) a triggering representation is weakened if the predictions it generates fail.
The result is that, often enough, the only only outcomes to which the observed action is a means
are represented strongly.

(*‘sometimes’ because the Motor Theory is part of a dual-process account of goal-tracking.)</div>
<!-- param @cls and param @options should be objects-->



<section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><p class="center"><span class="representational">goal ascription</span><span> &nbsp; &nbsp;</span><span class="functional hide">goal tracking</span></p><div class="notes">Two forms of goal ascription, representational and functional (\citealp{gallese:2011_what}).
In \emph{representational goal ascription}, three things must be represented: an action, an outcome and the relation between this outcome and the action in virtue of which the outcome is a goal of the action.
% jacob:2012_sharing: ‘Ascribing a goal to an agent consists in forming a belief (or judgment) about an agent that he or she has a goal or is performing some goal-directed action.’
In \emph{functional goal ascription}, the relation between action and outcome is captured without being represented.
To say that this relation is \emph{captured} is to say that there is a process which ensures that the outcome represented is a goal of the action.</div><div class="slide"><div data-what=".representational" data-css="{&quot;text-decoration&quot;:&quot;line-through&quot;}" class="dv dv-style"></div><div class="notes">Motor representations cannot suffice for representational goal ascription. 
It is true that, in someone observing an action there can be motor representations of outcomes which, non accidentally, are the goals of the observed action.
But this is not enough.
There would have to be, in addition, a motor representation of an intention, or of a motor representation or of some other goal-state, or of a function. 
But there are no such motor representations.</div></div><div class="slide"><div data-what=".functional" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div></div></div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><p>Own action:</p><p>Why are outcomes you represent motorically often among the goals of your actions?</p><div class="notes">How does it ever come about that an outcome represented motorically in observing an action is an outcome to which that action is directed?
First consider a parallel question about performing rather than observing actions.
Suppose you are alone and not observing or imagining any other actions.
When performing actions in this situation, outcomes represented motorically in you will normally be
among the goals of your actions; that is, they will be outcomes to which your actions are directed.
What ensures this correspondence between outcomes represented and goals?</div><div class="slide"><p>Because planning-like processes.</p><div class="notes">It is the role of the
representation in controlling how the action unfolds. Representations of outcomes trigger
planning-like motor processes whose function is to cause actions that will bring about the outcomes
represented \citep{miall:1996_forward,arbib:1985_coordinated,rosenbaum:2012_cognition}.</div></div><div class="slide"><p class="em-above">Another’s action</p><p>Why are outcomes you represent motorically often among the goals of her actions?</p><div class="notes">Now return to
observing rather than perform actions. What ensures the correspondence between outcomes represented
motorically and goals when you are merely observing another act?</div></div><div class="slide"><p>Because planning-like processes.</p><div class="notes">The answer, we suggest, is roughly that planning-like processes can be used not only to control
actions but also to predict them.
Let us explain.</div></div></div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/sinigaglia_butterfill_2005_fig1.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Sinigalia & Butterfill 2015, figure 1</p><div class="notes">There is evidence that a motor representation of an outcome can cause a determination of which movements are likely to be performed to achieve that outcome \citep[see, for instance,][]{kilner:2004_motor, urgesi:2010_simulating}. Further, the processes involved in determining how observed actions are likely to unfold given their outcomes are closely related, or identical, to processes involved in performing actions. 
This is known in part thanks to studies of how observing actions can facilitate performing actions congruent with those observed, and can interfere with performing incongruent actions \citep{
	brass:2000_compatibility, 
	craighero:2002_hand, 
	kilner:2003_interference, 
	costantini:2012_does}. 
Planning-like processes in action observation have also been demonstrated by measuring observers' predictive gaze.  If you were to observe just the early phases of a grasping movement, your eyes might jump to its likely target, ignoring nearby objects \citep{ambrosini:2011_grasping}. These proactive eye movements resemble those you would typically make if you were acting yourself \citep{Flanagan:2003lm}. 
Importantly, the occurrence of such proactive eye movements in action observation depends on your
representing the outcome of an action motorically; even temporary interference in the observer's
motor abilities will interfere with the eye movements \citep{Costantini:2012fk}.
These proactive eye movements also depend on planning-like processes; requiring the observer to
perform actions incongruent with those she is observing can eliminate proactive eye movements
\citep{Costantini:2012uq}. This, then, is further evidence for planning-like motor processes in
action observation.</div><div class="notes">So observers represent outcomes motorically and these representations trigger planning-like processes
which generate expectations about how the observed actions will unfold and their sensory consequences.
Now the mere occurrence of these processes is not sufficient to explain why, in action observation,
an outcome represented motorically is likely to be an outcome to which the observed action is
directed.</div><div class="notes">To take a tiny step further, we conjecture that, in action observation, \textbf{motor representations of
outcomes are weakened to the extent that the expectations they generate are unmet}
\citep[compare][]{Fogassi:2005nf}.
A motor representation of an outcome to which an observed action is not directed is likely to
generate incorrect expectations about how this action will unfold, and failures of these
expectations to be met will weaken the representation.
This is what ensures that there is a correspondence between outcomes represented motorically in
observing actions and the goals of those actions.</div></div></div></div></section><section class="slide"><div style="z-index:-22;" class="right-half-white"></div><div class="container_12"><div class="notes">Next I want to build on what we did in lecture 2 and argue that there is a further
puzzle.
The further puzzle concerns how motor representation may influence judgements about 
the goals of actions.</div><div class="notes">To see how the puzzle arises, I want to go back and reconsider the double life of 
motor representations. This is something I’ve already mentioned twice; now I want
to fill in some details that make it even more puzzling.</div><div class="grid_6 words left-half"><div style="padding-right:1em;"><p style="margin-top:125px;" class="center">Interface Problem</p><p class="hem-above">intention -> motor representation</p><p class="hem-above">How could intentions have content-respecting influences on motor representations given their inferential isolation?</p></div></div><div class="grid_6 words invert right-half"><div style="padding-left:1em;"><p style="margin-top:125px;" class="center">New Interface Problem</p><p class="hem-above">motor representation -> judgement</p><p class="hem-above">How could motor representations have content-respecting influences on thoughts given their inferential isolation?</p></div></div></div></section><section id="double_life_motor_representation" class="slide"><img src="/img/bkg/flowers/DSC_4550.low.JPG" class="bkg"/><div class="spacer">&nbsp;</div><div style="position:relative; top:425px" class="title-block"><div class="title-container"><h2 class="title1">The Double Life of Motor Representation</h2></div></div></section><div class="handout">&nbsp;</div><div class="handout">\section{The Double Life of Motor Representation}</div><div class="notes notes-header-tex">&nbsp;</div><div class="notes notes-header-tex">\section{The Double Life of Motor Representation}</div><div class="notes">Motor representations live a kind of double life. Although paradigmatically involved in performing
actions, they also occur when merely observing others act and sometimes influence thoughts about the
goals of observed actions. Further, these influences are content-respecting: what you think about an
action sometimes depends in part on how that action is represented motorically in you.</div>
<!-- param @cls and param @options should be objects-->



<div class="notes">- - - - - - - -</div><div class="notes">Suppose you are reaching for, grasping, transporting and then placing a pen. Performing even
relatively simple action sequences like this involves satisfying many constraints that cannot
normally be satisfied by explicit practical reasoning, especially if performance is to be rapid and
fluent. Rather, such performances require motor representations.
These representations are paradigmatically involved in preparing, executing and monitoring actions.%
\footnote{%
See \citet{wolpert:1995internal, miall:1996_forward, jeannerod:1998nbo, zhang:2007_planning}.
Note that motor representations sometimes occur in an agent who has prepared an action and is required (as it turns out) not to perform it: although she has prevented herself from acting, motor representations specifying the action persist, perhaps because they are necessary for monitoring whether prevention has succeeded \citep{bonini:2014_ventral}.
}
But they also live a double life. Motor representations concerning a particular type of action are
involved not only in performing an action of that type but also sometimes in observing one. That is,
if you were to observe Ayesha reach for, grasp, transport and then place a pen, motor representations
would occur in you much like those that would also occur in you if it were you---not Ayesha---who was
doing this.</div><div class="notes">Converging evidence for this assertion comes from a variety of methods and measures ...</div><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/fogassi_2005_fig1B.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Fogassi et al 2005, figure 1B</p><div class="notes">Single cell recordings in nonhuman primates show that, for each of several types of action, there are
populations of neurons that discharge both when an action of this type is performed and when one is
observed \citep{pellegrino:1992_understanding, gallese:1996_action,Fogassi:2005nf}.</div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/fogassi_2005_fig1C.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Fogassi et al 2005, figure 1B</p><div class="notes">This is the performance data.</div><div class="notes">Note that the neurons are firing before the distinctive part of the action has
occured: that is, the peak is between movement onset and the monkey first touching
the object to be grasped.</div><div class="notes">Now let’s compare 
performance with observation.</div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><img src="/img/fogassi_2005_fig5.png" style=""/><p class="source">Fogassi et al 2005, figure 5</p><div class="notes">‘(A) Congruence between the visual and the motor response of a mirror neuron. Unit 169 has a stronger
discharge during grasping to eat than during grasping to place, both when the action is executed and
when it is observed. Conventions as in Fig. 1. (B) Population-averaged responses during motor and
visual tasks (12).’</div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="handout notes"><p>‘word listening produces a phoneme specific activation of speech motor centres’ \citep{Fadiga:2002kl}</p><p class="em-above">‘Phonemes that require in production a strong activation of tongue muscles, automatically produce, when heard, an activation of the listener's motor centres controlling tongue muscles.’ \citep{Fadiga:2002kl}</p></div><p>‘word listening produces a phoneme specific activation of speech motor centres’ </p><div class="slide"><p class="em-above">‘Phonemes that require in production a strong activation of tongue muscles, automatically produce, when heard, an activation of the listener's motor centres controlling tongue muscles.’ </p><div class="notes">Good, but this stops short of showing that the motor activations
actually faciliatate speech recognition ...</div></div><p class="right grey-text">Fadiga et al (2002)</p><div class="notes">How did they reach these conclusions?</div><div class="slide em-above"><p>bi<span class="rr">rr</span><span>a / be</span><span class="rr">rr</span><span>o (pseudo-word) / ba</span><span class="ff">ff</span><span>o</span></p><div class="slide"><div data-what=".rr" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".rr" data-cls="bkg-yellow" class="dv dv-addclass"></div><div class="notes">Inovlves tongue</div></div><div class="slide"><div data-what=".ff" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".ff" data-cls="bkg-blue" class="dv dv-addclass"></div><div class="notes">No tongue required</div><div class="notes">Given TMS to motor cortex tp amplify activity.
Prediction: MEP in tongue muscle stronger for ‘rr’ than ‘ff’.</div></div></div></div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/fadiga_2002_fig2.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Fadiga et al 2002, figure 2</p></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><img src="/img/bruderer_2015_fig5.png" width="720px" style="filter:invert(1);"/><p class="source">Bruderer et al, 2015 figures 1, 4</p><div class="notes">Experiment 1 : shows that 6-month-old infants can distinguish a phonetic contrast
they have never heard before (one that occurs in Hindi but not their linguistic 
environments.) (The contrast used was the Hindi dental /d/̪ versus retroflex /ɖ/
distinction.)</div><div class="notes">These graphs show a difference in mean looking time between cases in which phonemes 
are alternated and cases in which they are not. (Iff infants distinguish, they should
find the alternating phonemes more interesting.)</div><div class="notes">Experiment 2: but not when they have a tongue-controlling dummy in their mouths</div><div class="notes">Experiment 3: but yes when they have a dummy which leaves the tongue free.</div></div></div></div></section><section style="" class="slide"><img src="/img/kilner_2003/Slide1.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><div class="notes">Behaviour: interference effects (ovalization)</div></div></div></div></section><section style="" class="slide"><img src="/img/kilner_2003/Slide2.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/kilner_2003/Slide3.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/kilner_2003/Slide4.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/kilner_2003/Slide5.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/kilner_2003/Slide6.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="notes show"><p class="center huge-glow">Old Puzzle </p><p style="margin-top:-3em;" class="center below-huge-glow">What are those motor representations doing here?</p></div><div class="notes">But there is also another puzzle ...</div></div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><p class="center">Motor representations in observation facilitate anticipation of others’ actions.</p></div></div></div></div></section><section style="" class="slide"><img src="/img/costantini_2002.png" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">Costantini et al, 2012</p><div class="notes">‘We recorded proactive eye movements while participants observed an actor grasping small or large
objects. The participants' right hand either freely rested on the table or held with a suitable grip
a large or a small object, respectively. Proactivity of gaze behaviour significantly decreased when
participants observed the actor reaching her target with a grip that was incompatible with respect to
that used by them to hold the object in their own hand.’</div><div class="notes">Follow ups: tie hands; TMS (impair)</div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><p class="center">Motor representations in observation facilitate explicit identification of others’ actions.</p></div></div></div></div></section><section style="" class="slide"><img src="/img/casile_giese_fig1.png" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">Casile & Giese 2006, figure 1</p><div class="notes">Ability to perform actions: the 180 degree swing is standard walk, whereas
225 and 270 degree swings are not standard but can be trained.</div><div class="notes">Visual discrimination task: ‘The visual recognition experiment was based on a forced-choice
paradigm. In each trial, two point-light stimuli consisting of a total of nine dots were presented
successively, at two different positions on the screen ... Participants had to respond whether both
stimuli represented the same gait pattern. Four cycles of each gait pattern were presented, each
cycle lasting for about 1.2 s. The start position within the gait cycle was randomized across
trials.’</div><div class="notes">Then training while BLINDFOLDED.</div><div class="notes">Then visual recognition task again.</div><div class="notes">‘One possible explanation of the observed motor-visual transfer is that the
participants might have picked up the rhythm that characterizes the trained
motor pattern, but not necessarily the details of the learned body
movement. To rule out this possibility, we performed a control experiment
in which the motor training was replaced by purely visual training.’</div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/casile_giese_fig4A.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Casile & Giese 2006, figure 4A</p><div class="notes">Visual performance correlates with motor performance after (but not before) training.
(They also found no correlation with 225 degrees, which was not trained.)</div><div class="notes">This effect is perhaps surprising given that your judgement ultimately rests on purely visual
information (this is the point of the lights) whereas nothing could be seen during the training.</div><div class="notes">What explains this difference in judgement before and after training?  Training of this kind typically alters the way things are represented motorically \citep{Calvo-Merino:2006ru}.
\label{expertise_affects_motor}
For this reason, the increase in the probability of making accurate judgements about the goals of others' actions is plausibly a consequence of differences in motor representations in the observer.</div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/pazzaglia_fig1bi.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Pazzaglia et al 2007, figure 1B (part)</p><div class="notes">task: hear sound, identify one of four pictures.</div><div class="notes">Twenty-eight left-hemisphere-damaged patients with or without limb and/or buccofacial apraxia and
seven right- hemisphere-damaged patients with no apraxia were asked to match sounds evoking
human-related actions or nonhu- man action sounds with specific visual pictures.</div><div class="notes">‘In the novel sound-picture matching test used in this study, each patient was asked to listen to a
sound and then choose from among four pictures the one corresponding to the heard sound. The sounds
used included limb-related action sounds (LRAS), buccofacial-related action sounds (BRAS)
[ten sounds were transitive, i.e., object related (e.g., inflating a balloon) and ten were
intransitive, i.e., non object related (e.g., coughing). ], and non-human action-related sounds
(NHARS) [e.g. sea waves, breaking]’</div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/pazzaglia_fig1bii.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Pazzaglia et al 2007, figure 1B (part)</p></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/pazzaglia_2008_S1.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Pazzaglia et al 2007, Appendix S1 (fragment)</p></div></div></div></section><section style="" class="slide"><img src="/img/pazzaglia_2008_fig2.png" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">Pazzaglia et al 2007, figure 2</p><div class="notes">Beautiful results!</div><div class="notes">Key: limb-related action sounds (LRAS), buccofacial-related action sounds (BRAS), and non-
human action-related sounds (NHARS)</div><div class="notes">A+ apraxia; AB+ : buccofacial apraxia; AL+ limb apraxia; LBD: left brain damage; RBD: right brain damage</div></div></div></div></section><section style="" class="slide"><img src="/img/dausilio_2009_fig1.png" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">D'Ausilio et al (2009, figure 1)</p><div class="notes">‘Double TMS pulses were applied just prior to stimuli presentation to selectively prime the cortical activity specifically in the lip (LipM1) or tongue (TongueM1) area’
\citep[p.~381]{dausilio:2009_motor}</div><div class="notes">‘We hypothesized that focal stimulation would facilitate the perception of 
the concordant phonemes ([d] and [t] with TMS to TongueM1), but that 
there would be inhibition of perception of the discordant items 
([b] and [p] in this case). Behavioral effects were measured via reaction 
times (RTs) and error rates.’ \citep[p.~382]{dausilio:2009_motor}</div></div></div></div></section><section style="" class="slide"><img src="/img/dausilio_2009_fig2.png" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">D'Ausilio et al (2009, figure 1)</p><div class="notes">‘Effect of TMS on RTs show a double dissociation between stimulation 
site (TongueM1 and LipM1) and discrimination performance between class 
of stimuli (dental and labial). The y axis represents the amount of RT 
change induced by the TMS stimulation. Bars depict SEM. Asterisks 
indicate significance (p < 0.05) at the post-hoc (Newman-Keuls) comparison.’ 
\citep{dausilio:2009_motor}</div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="notes show"><p class="huge-glow-70">Old Puzzle</p><p style="margin-top:-2em;" class="below-huge-glow">What are those motor representations doing here?</p><div class="slide"><p class="right em-above">Motor representations concerning the goals of observed actions sometimes facilitate the identification of goals.</p></div><div class="slide"><p class="center huge-glow-70">New Question</p><p style="margin-top:-2em;" class="center"> How?</p></div></div><div class="notes">Question: How is it that motor representations concerning the goals of observed actions sometimes facilitate identification of goals?</div></div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><p class="hem-around">In action observation, motor representations of outcomes </p><p class="hem-around step3 hide">sometimes facilitate the identification of goals in thought.</p><div class="slide"><div data-what=".step3" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div></div><div class="slide"><p class="em-above">So</p><p>where motor representations influence a thought about an action being directed to a
particular outcome, there is normally a motor representation of this outcome, or of a
matching outcome.</p><div class="notes">This conclusion entails that motor representations have content-respecting
influences on thoughts. It is the fact that one outcome rather than another is represented
motorically which explains, at least in part, why the observer takes this outcome (or a matching
one) to be an outcome to which the observed action is directed.</div></div><div class="slide"><p class="em-above">But</p><p>how could motor representations have content-respecting influences on thoughts <span class="step4 hide">given their inferential isolation</span><span>?</span></p><div class="notes">But how could motor representations
have content-respecting influences on thoughts? One familiar way to explain content-respecting
influences is to appeal to inferential relations. To illustrate, it is no mystery that your beliefs
have content-respecting influences on your intentions, for the two are connected by processes of
practical reasoning. But motor representation, unlike belief and intention, does not feature in
practical reasoning. Indeed, thought is inferentially isolated from it. How then could any motor
representations have content-respecting influences on thoughts?</div><div class="slide"><div data-what=".step4" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div></div></div></div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div id="timer1" class="timer-outer"><div class="timer center timer-120s "><div class="mask"></div></div><div class="timer-120s-block-wrapper"><div class="timer-120s-block"><p class="center"> <span>How do motor representations</span><br/><span>have content-respecting influences</span><br/><span>on thoughts?</span></p></div></div></div><div class="slide"><div data-what="#timer1 .timer.hide" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:0}" class="dv dv-velocity"></div><div data-what="#timer1 .timer" data-cls="running" class="dv dv-addclass"></div></div></div></div></div></div></section><div class="handout">&nbsp;</div><div class="handout">\section{The Twin Interface Problems}</div><div class="notes notes-header-tex">&nbsp;</div><div class="notes notes-header-tex">\section{The Twin Interface Problems}</div><div class="notes">How could intentions have content-respecting influences on motor representations given their inferential isolation?
And how could motor representations have content-respecting influences on thoughts given their inferential isolation?</div>
<!-- param @cls and param @options should be objects-->



<section class="slide"><div style="z-index:-22;" class="right-half-white"></div><div class="container_12"><div class="notes">So here are my two puzzles ...
The first one comes straight from lecture 01; the second is new, but based on 
ideas discussed in Lecture 02.</div><div class="grid_6 words left-half"><div style="padding-right:1em;"><p style="margin-top:125px;" class="center">Interface Problem</p><p class="hem-above">intention -> motor representation</p><p class="hem-above">How <span class="could">could</span><span> intentions have content-respecting influences on motor representations given their inferential isolation?</span></p></div></div><div class="grid_6 words invert right-half"><div style="padding-left:1em;"><p style="margin-top:125px;" class="center">New Interface Problem</p><p class="hem-above">motor representation -> judgement</p><p class="hem-above">How <span class="could">could</span><span> motor representations have content-respecting influences on thoughts given their inferential isolation?</span></p></div></div></div></section></div></body></html>