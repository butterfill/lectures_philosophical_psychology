
<!-- - scripts.add(["/vendor/deck.js/deck.core.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.menu.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.hash.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.notes.js"])--><html><head><!-- (c) copyright 2013 Stephen A. Butterfill--><meta charset="utf-8"/><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><title>Adaptation and Launching | Philosophical Psychology</title><meta name="description" content="  "/><meta name="keywords" content="philosophy, psychology, action, joint action, metarepresentation, perception"/><meta name="author" content=""/><meta name="generator" content="DocPad v6.78.4" /><meta name="viewport" content="width=device-width"/><!-- - lato font--><link href="https://fonts.googleapis.com/css?family=Lato:300,400,900,400italic" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=The+Girl+Next+Door" rel="stylesheet" type="text/css"/><!--if lt IE 9script(async src="http://html5shim.googlecode.com/svn/trunk/html5.js")
--><link  rel="stylesheet" href="/vendor/boilerplate.min.css" /><link  rel="stylesheet" href="/vendor/normalize.min.css" /><link  rel="stylesheet" href="/vendor/deck.js/deck.all.min.css" /><link  rel="stylesheet" href="/vendor/960_12_col_custom.min.css" /><link  rel="stylesheet" href="/styles/steve_deck_style.css" /><link  rel="stylesheet" href="/vendor/questionmark.js/question.mark.css" /></head><body><script defer="defer"  src="/vendor/jquery.min.js"></script><script defer="defer"  src="/vendor/jquery-svgfix.js"></script><script defer="defer"  src="/vendor/jquery.crSplineBkg.js"></script><script defer="defer"  src="/vendor/velocity.min.js"></script><script defer="defer"  src="/vendor/marked.min.js"></script><script defer="defer"  src="/vendor/modernizr.custom.01932.js"></script><script defer="defer"  src="/vendor/deck.js/deck.velocity.js"></script><script defer="defer"  src="/vendor/deck.js/deck.all.min.js"></script><script defer="defer"  src="/vendor/jquery.jsPlumb-1.3.16-all-min.js"></script><script defer="defer"  src="/scripts/script.js"></script><script defer="defer"  src="/vendor/questionmark.js/question.mark.min.js"></script><div id="helpUnderlay" class="help-underlay"><div id="helpModal" class="help-modal"><h1>Keyboard Shortcuts<kbd class="help-key"><span>?</span></kbd></h1><div id="helpClose" class="help-close">×</div><!-- .help-close--><div id="helpModalContent" class="help-modal-content"><div id="helpListWrap" class="help-list-wrap"><ul class="help-list"><li class="help-key-unit"><kbd class="help-key"><span>→</span></kbd><span class="help-key-def">Next step</span></li><li class="help-key-unit"><kbd class="help-key"><span>←</span></kbd><span class="help-key-def">Previous step</span></li><li class="help-key-unit"><kbd class="help-key"><span>↓</span></kbd><span class="help-key-def">Skip this slide</span></li><li class="help-key-unit"><kbd class="help-key"><span>↑</span></kbd><span class="help-key-def">Previous slide</span></li><li class="help-key-unit"><kbd class="help-key"><span>m</span></kbd><span class="help-key-def">Show slide thumbnails</span></li><li class="help-key-unit"><kbd class="help-key"><span>n</span></kbd><span class="help-key-def">Show notes</span></li><li class="help-key-unit"><kbd class="help-key"><span>h</span></kbd><span class="help-key-def">Show handout latex source</span></li><li class="help-key-unit"><kbd class="help-key"><span>N</span></kbd><span class="help-key-def">Show talk notes latex source</span></li></ul><!-- .help-list--></div><!-- .help-list-wrap--></div><!-- .help-modal-content--></div><!-- .help-modal--></div><!-- .help-underlay-->
<div class="deck-notes"><div class="deck-notes-container"></div></div><div class="deck-handout"><div class="deck-handout-container"></div></div><div class="deck-container"><section id="instructions" class="slide"><div class="words"><div class="container_12"><div class="grid_12"><div class="middle"><p class="center">Click here and press the right key for the next slide (or swipe left)</p></div></div></div></div></section><section class="slide"><!-- .notes You won't believe how many people emailed me to say the slides don't work.--><div class="words"><div class="container_12"><div class="grid_12"><p>also ...</p><p>Press the left key to go backwards (or swipe right)</p><p>Press n to toggle whether notes are shown (or add '?notes' to the url before the #)</p><p>Press m or double tap to slide thumbnails (menu)</p><p>Press ? at any time to show the keyboard shortcuts</p></div></div></div></section><section id="adaptation_causal" class="slide"><div class="spacer">&nbsp;</div><div style="" class="title-block"><div class="title-container"><h2 class="title1">Adaptation and Launching</h2></div></div></section>
<!-- param @cls and param @options should be objects-->



<section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="notes"> A challenge to the conjecture ...</div><div class="notes">A question was:</div><p class="notes ctd show">Can humans perceive causal interactions?</p><div class="notes">Now I think we have achieved an answer:</div><p class="indent em-above notes show"><span>Working hypothesis: Causal interactions are detected, or otherwise treated specially, by   </span><span class="processes">perceptual processes</span><span> involved in segmenting and tracking objects.</span></p></div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/rolfs_2013_fig1.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Rolfs et al, 2013 figure 1 (part)</p></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/rolfs_2013_fig2b.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Rolfs et al, 2013 figure 2B</p></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div style="position:relative;"><img src="/img/arnold_2015_fig1.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div><p class="source">Arnold et al 2015, figure 1</p><notes>‘participants were asked to judge whether simulated bounces of a disc against a static wedge were
‘‘hard’’ (like a pool ball bouncing on concrete) or ‘‘soft’’ (like a squash ball bouncing).’</notes><notes>‘ Adaptation suggesting repeated ‘‘rigid’’ collisions resulted in more ‘‘soft’’ bounces being reported, whereas adaptation suggesting repeated elastic object collisions resulted in more ‘‘hard’’ bounce reports—an object elasticity aftereffect.’</notes></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><p class="center">adaptation</p><div class="notes">This seems hard to reconcile with object indexes.
But (A) note the questions in the commentary; and (B) Hubbard on Kiritani (1999)
for launching when the contact is occluded; and context effects (Scholl on postdiction)
and (D) evidence for effects of 
acoustic stimuli on launching, suggesting that the effect may not be modality-specific
(The evidence on this point is controversial. Sekuler and colleagues show that when subjects observe
an ambiguous visual display consistent with either a collision or a passing event, the timing of a
tone can control whether subjects report seeing a collision or pass- ing, and argue that this is a
multisensory phenomenon: R. Sekuler et al., ‘Sound Alters Visual Motion Perception’, Nature, 
(), p. . Watanabe and Shimojo extend this finding by showing that not any event (or
non-event) which draws attention at the moment of a collision will disambiguate the display; they
argue that the tone’s effect on the perception of a col- lision is a ‘genuine audiovisual effect,
not an audiovisual effect that results from auditory effects’: K. Watanabe and S. Shimojo, ‘When
Sound Affects Vision: Effects of Auditory Grouping on Visual Motion Perception’, Psychological
Science,  (), pp. –. Guski and Troje, on the other hand, show that features which carry
no information about causation, such as a blink, can also influence whether subjects report seeing a
collision or a passing. These authors conclude that auditory influences on the perceptual of
collisions are ‘no true cross-modal phenomenon’: R. Guski and N.F. Troje, ‘Audiovisual Phenomenal
Causality’, Perception and Psychophysics,  (), pp. –, at p. .)</div></div></div></div></div></section></div></body></html>