

<!-- - scripts.add(["/vendor/deck.js/deck.core.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.menu.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.hash.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.notes.js"])-->
<html>
  <head>
    <!-- (c) copyright 2013 Stephen A. Butterfill-->
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <title>Speech Perception | Philosophical Psychology</title>
    <meta name="description" content="***"/>
    <meta name="keywords" content="philosophy, psychology, action, joint action, metarepresentation, perception"/>
    <meta name="author" content=""/><meta name="generator" content="DocPad v6.78.4" />
    <meta name="viewport" content="width=device-width"/>
    <!-- - lato font-->
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,900,400italic" rel="stylesheet" type="text/css"/>
    <link href="https://fonts.googleapis.com/css?family=The+Girl+Next+Door" rel="stylesheet" type="text/css"/>
    <!--if lt IE 9
    script(async src="http://html5shim.googlecode.com/svn/trunk/html5.js")
    
    --><style >html.wait {
	cursor: wait !important;
	opacity: 0;
	transition: opacity 0.5s ease;
}</style><link  rel="stylesheet" href="/vendor/boilerplate.min.css" /><link  rel="stylesheet" href="/vendor/normalize.min.css" /><link  rel="stylesheet" href="/vendor/deck.js/deck.all.min.css" /><link  rel="stylesheet" href="/vendor/960_12_col_custom.min.css" /><link  rel="stylesheet" href="/styles/steve_deck_style.css" /><link  rel="stylesheet" href="/vendor/questionmark.js/question.mark.css" />
  </head>
  <body><script >(function(){
	/* Did we just livereload? */
var log = !!(localStorage && console && console.log && true);
if ( log && localStorage.getItem('/docpad-livereload/reloaded') === 'yes' ) {
	localStorage.removeItem('/docpad-livereload/reloaded');
	console.log('LiveReload completed at', new Date())
}

/* Listen for the regenerated event and perform a reload of the page when the event occurs */
var listen = function(){
	var primus = new Primus('/docpad-livereload');
	primus.on('data', function(data){
		if ( data && data.message ) {
			if ( data.message === 'generateBefore' ) {
				if ( log ) {
					console.log('LiveReload started at', new Date());
				}
				if ( typeof document.getElementsByTagName !== 'undefined' ) {
	document.getElementsByTagName('html')[0].className += ' wait';
}
			}
			else if ( data.message === 'generateAfter' ) {
				if ( log ) {
					localStorage.setItem('/docpad-livereload/reloaded', 'yes');
				}
				document.location.reload();
			}
		}
	});
};
	/* Inject socket into our page */
var inject = function(){
	var t = document.createElement('script');
	t.type = 'text/javascript';
	t.async = 'async';
	t.src = '/primus/primus.js';
	t.onload = listen;
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(t, s);
};
	if ( typeof Primus !== 'undefined' ) {
		listen();
	} else {
		inject();
	}
})();</script><script defer="defer"  src="/vendor/jquery.min.js"></script><script defer="defer"  src="/vendor/jquery-svgfix.js"></script><script defer="defer"  src="/vendor/jquery.crSplineBkg.js"></script><script defer="defer"  src="/vendor/velocity.min.js"></script><script defer="defer"  src="/vendor/marked.min.js"></script><script defer="defer"  src="/vendor/modernizr.custom.01932.js"></script><script defer="defer"  src="/vendor/deck.js/deck.velocity.js"></script><script defer="defer"  src="/vendor/deck.js/deck.all.min.js"></script><script defer="defer"  src="/vendor/jquery.jsPlumb-1.3.16-all-min.js"></script><script defer="defer"  src="/scripts/script.js"></script><script defer="defer"  src="/vendor/questionmark.js/question.mark.min.js"></script>
    <div id="helpUnderlay" class="help-underlay">
      <div id="helpModal" class="help-modal">
        <h1>Keyboard Shortcuts<kbd class="help-key"><span>?</span></kbd></h1>
        <div id="helpClose" class="help-close">×</div>
        <!-- .help-close-->
        <div id="helpModalContent" class="help-modal-content">
          <div id="helpListWrap" class="help-list-wrap">
            <ul class="help-list">
              <li class="help-key-unit"><kbd class="help-key"><span>→</span></kbd><span class="help-key-def">Next step</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>←</span></kbd><span class="help-key-def">Previous step</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>↓</span></kbd><span class="help-key-def">Skip this slide</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>↑</span></kbd><span class="help-key-def">Previous slide</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>m</span></kbd><span class="help-key-def">Show slide thumbnails</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>n</span></kbd><span class="help-key-def">Show notes</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>h</span></kbd><span class="help-key-def">Show handout latex source</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>N</span></kbd><span class="help-key-def">Show talk notes latex source</span></li>
            </ul>
            <!-- .help-list-->
          </div>
          <!-- .help-list-wrap-->
        </div>
        <!-- .help-modal-content-->
      </div>
      <!-- .help-modal-->
    </div>
    <!-- .help-underlay-->
    
    <div class="deck-notes">
      <div class="deck-notes-container"></div>
    </div>
    <div class="deck-handout">
      <div class="deck-handout-container"></div>
    </div>
    <div class="deck-container">
      <section id="instructions" class="slide">
        <div class="words">
          <div class="container_12">
            <div class="grid_12">
              <div class="middle">
                <p class="center">Click here and press the right key for the next slide (or swipe left)</p>
              </div>
            </div>
          </div>
        </div>
      </section>
      <section class="slide">
        <!-- .notes You won't believe how many people emailed me to say the slides don't work.-->
        <div class="words">
          <div class="container_12">
            <div class="grid_12">
              <p>also ...</p>
              <p>Press the left key to go backwards (or swipe right)</p>
              <p>Press n to toggle whether notes are shown (or add '?notes' to the url before the #)</p>
              <p>Press m or double tap to slide thumbnails (menu)</p>
              <p>Press ? at any time to show the keyboard shortcuts</p>
            </div>
          </div>
        </div>
      </section>
      <section id="categorical_perception_speech" class="slide">
        <div class="spacer">&nbsp;</div>
        <div style="" class="title-block">
          <div class="title-container">
            <h2 class="title1">Speech Perception</h2>
          </div>
        </div>
      </section>

<!-- param @cls and param @options should be objects-->




<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">articulatory gesture</p>
          <div class="notes">In speaking we produce an overlapping sequence of articulatory gestures, which are motor actions
involving coordinated movements of the lips, tongue, velum and larynx. These gestures are the units
in terms of which we plan utterances (Browman and Goldstein 1992; Goldstein, Fowler, et al. 2003).
          </div>
          <div class="notes">These are the actions I want to focus on first in thinking about
what we experience when we encounter others’ actions.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div style="position:relative;"><img src="/img/browman_1996_fig1.png" style="clip: auto; position: absolute; max-width:720px; max-height:550px;"/></div>
        <p class="source">Browman & Goldstein 1986, figure 1</p>
        <div class="notes">
          ;t
          ‘Trajectory of lower lip in [abe] as measured by tracking infra-redLED placed on subject's lower lip’
        </div>
        <div class="notes">‘Not every utterance of word transcribed with /b/ will display exactly the trajectory
of Fig. 1.: the trajectory will vary with vowel context, syllable position,
stress, speaking rate and speaker.
We must, therefore, ultimately characterise /b/ as a family of patterns of lip
movement’
\citep[p.~224]{browman:1986_towards}
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">Speech and auditory perception involve distinct processes</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/duplex_01.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">A schematic spectrogram for a synthetic sound which is normally perceived as [ra]. The horizontal
axis represents time, the vertical frequency.
        </div>
        <div class="notes">A schematic spectrogram for [la].
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/duplex_02.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">In the middle you see the \emph{base}, i.e. the part of the spectrogram common to [ra] and [la]. This
is played to one ear
        </div>
        <div class="notes">Below you see the transitions, , i.e. the parts of the spectrogram that differ between [ra] and [la].
When played in isolation these sound like a chirp. When played at the same time as the base but in
the other ear, subjects hear a chirp and a [ra] or a [la] depending on which transition is played.
        </div>
        <div class="notes">How do we know that the same stimuli may be processed by different perceptual systems
concurrently—for instance, how do we know that speech and auditory processing are distinct? A
phenomenon called “duplex” perception demonstrates their distinctness occurs in. Artificial
speech-like stimuli for two syllables, [ra] and [la], are generated. The acoustic signals for each
syllable is artificially broken up into two parts, the “base” and “transition” (see Fig. *** below).
The syllables have the same “base” but differ in the “transition”. When the “transition” is played
alone it sounds like a chirp and quite unlike anything we normally hear in speech. Duplex perception
occurs when the base and transition are played together but in separate ears. In this case, subjects
hear both the chirp that they hear when the transition is played in isolated, and the syllable [la]
or [ra]. Which syllable they hear depends on which transition is played, so speech processing must
have combined the base and transition. By contrast, auditory processing must have failed to combine
them because otherwise the chirp would not have been heard. In this case, then, the perception
resulting from the duplex presentation involves simultaneous auditory and speech recognition
processes. This shows that auditory and speech processing are distinct perceptual processes.
        </div>
        <div class="notes">The duplex case is unusual. We can’t normally hear the chirps we make in speaking because speech
processing inhibits this level of auditory processing. But plainly speech is subject to some auditory
processing for we can hear extra-linguistic qualities of speech; some of these provide cues to
emotional state, gender and class. Perception of these extra-linguistic qualities enables us to
distinguish stimuli within a category. As already mentioned, this is a problem for Repp’s operational
definition. Our ability to discriminate stimuli is the product of both categorical speech processing
and non-categorical auditory processing. If we want to get at the essence of categorical perception
it seems there is no alternative but to appeal to particular perceptual processes rather than
behaviours.
        </div>
        <div class="notes">Source: \citep{Liberman:1981xk}</div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide01.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Here are 12 speech-like sounds.
Acoustically each differs from its neighbours no more than any other does.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide02.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">They would be labelled differently
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide03.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">And within a label they are relatively hard to disciminate whereas ...
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide04.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Discriminating acoustically no less similar stimuli that are given
different labels is easier (faster and more accurate).
        </div>
        <div class="notes">This is categorical perception: speed and accuracy maps onto labelling ...
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide06.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">Categorical perception of mating calls and perhaps other acoustic signals is widespread in non-human
animals including monkeys, mice and chinchillas (Ehret 1987; Kuhl 1987), and is even found in
cognitively unsophisticated animals such as frogs (Baugh, Akre and Ryan 2008) and crickets
(Wyttenbach, May and Hoy 1996).
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">What are the objects of categorical perception?</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide26.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">the location of the category boundaries changes depending on contextual factors such as the
speaker’s dialect,22 or the rate at which the speaker talks;23 both factors dramatically affect
which sounds are produced.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide27.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">This means that in two different contexts, different stimuli may result in the same perceptions, and
the same stimulus may result in different perceptions.
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide23.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide24.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide25.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">co-articulation, the fact that phonic gestures overlap (this is what makes talking fast).
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">What are the objects of categorical perception?</p>
          <div class="notes show em-above">
            <p class="em-around">1. Speech perception is categorical</p>
            <p class="em-around">  2. The category boundaries correspond (imperfectly but robustly) to differences in articulatory gestures</p>
            <p class="em-around">  3.  The best explanation of (2) involves the hypothesis that the objects of speech perception are articulatory gestures</p>
          </div>
          <div class="notes">\emph{Articulatory Gesture:}
In speaking we produce an overlapping sequence of articulatory gestures, which are motor actions
involving coordinated movements of the lips, tongue, velum and larynx. These gestures are the units
in terms of which we plan utterances (Browman and Goldstein 1992; Goldstein, Fowler, et al. 2003).
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p>The objects of speech perception are articulatory gestures.</p>
          <p class="em-above">... Does this entail that we perceptually experience articulatory gestures?</p>
          <div class="slide">
            <p class="em-above">‘Describing [Mary’s experience] as being as of a dodecahedron … is … normally intended to describe its introspectable character’</p>
            <p class="grey-text right">(Martin 1992: 762).</p>
          </div>
          <div class="slide">
            <p class="em-above">Perceptual experiences are reasons for beliefs ...</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">An argument for perceptual experience of articulatory gestures.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide06.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide07.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide08.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide09.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
      </div>
    </div>
  </div>
</section>
<section class="slide"><img src="/img/categorical_perception_of_speech/Slide10.jpg" width="1024px" class="bkg"/>
  <div class="words">
    <div class="container_12">
      <div class="grid_12">
        <div class="notes">The difference in differences ...
        </div>
        <div class="notes">Here is the argument. Consider two sequences of sensory encounters: (a) a sequence of sensory
encounters with two phonetic events that do not differ with respect to category (both are
realisations of /d/, say), and (b) a sequence of sensory encounters with two phonetic events that do
so differ (one is a realisation of /d/ the other of /g/, say).11 Let the events encountered in the
first sequence differ from each other acoustically in the same way and by the same amount as the
events encountered in the second sequence differ from each other. (That it is possible to find two
such pairs of events follows from the fact that we enjoy categorical perception of speech.) The two
sequences are depicted in Fig. 3. Now:
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="hem-around">(1) The second sequence of sensory encounters, (b), differ from each other more in phenomenal character than the first sequence of sensory encounters, (a), differ from each other.</p>
          <p class="hem-around slide">(2) This difference in differences in phenomenal character is a fact in need of explanation.</p>
          <p class="hem-around slide">(3) The difference cannot be fully explained by appeal only to perceptual experiences as of acoustic features of the stimuli.</p>
          <p class="hem-around slide">(4) The difference can be explained in terms of perceptual experiences as of phonetic properties.</p>
          <p class="hem-around slide">(5) There is no better explanation of the difference.</p>
          <div class="notes">The fourth step in this argument, (4), needs some filling in. How would the thesis that categorical
perception of speech is a form of perceptual experience explain the difference in differences in
phenomenal character? If the thesis is true, the first sequence of sensory encounters, (a), involves
two perceptual experiences as of a single phoneme whereas the second sequence of encounters, (b),
involves perceptual experiences as of different phonemes.12 Let us assume (not very controversially)
that perceptual experiences have phenomenal characters and that which phenomenal character a
perceptual experience has depends in part on what it is as of.13 It follows that differences in what
perceptual experiences are as of can explain differences in the phenomenal characters of those
perceptual experiences. In particular, if it is a fact that (b) involves perceptual experiences as
of different things whereas (a) does not, this could explain why the sensory encounters in (b)
differ in phenomenal character in a way that the sensory encounters in (a) do not.
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">Recall the question ...
          </div>
          <p class="center">What do we experience when we encounter others’ <span class="speech">speech </span><span> actions?</span></p>
          <p class="em-above center">Indirect Hypothesis vs  <span class="direct-h">Direct Hypothesis</span></p>
          <div class="slide">
            <div data-what=".direct-h" data-cls="transition-04" class="dv dv-addclass"></div>
            <div data-what=".direct-h" data-cls="bkg-invert" class="dv dv-addclass"></div>
          </div>
          <div class="notes">It looks like the Direct Hypothesis wins, or at least that we must reject the 
Indirect Hypothesis.
          </div>
          <div class="notes">There’s just one little problem ...
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="notes handout show">How could the objects of categorical perception of speech be articulatory gestures?</p>
          <div class="notes">The puzzle here is simple.
Categorical perception of speech happens raidly, and goal-directed actions
are complex.  How can something so complex be computed so quickly?
          </div>
          <div class="slide">
            <p class="em-above notes handout show">‘Humans [can] understand speech delivered at a rate of 20 to 30 ... phonemes per second’
            </p>
            <div class="notes handout ctd"> \citep{Devlin:2006qg}</div>
            <p class="right grey-text">Devlin (2006)</p>
            <div class="notes">Before facing this problem directly, I want to think about action more generally ...
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
    </div>
  </body>
</html>