

<!-- - scripts.add(["/vendor/deck.js/deck.core.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.menu.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.hash.js"])-->
<!-- - scripts.add(["/vendor/deck.js/deck.notes.js"])-->
<html>
  <head>
    <!-- (c) copyright 2013 Stephen A. Butterfill-->
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <title>The Objects of Categorical Perception | Philosophical Psychology</title>
    <meta name="description" content="Slides for a lecture by s.butterfill@warwick.ac.uk"/>
    <meta name="keywords" content="philosophy, psychology, action, joint action, metarepresentation, perception"/>
    <meta name="author" content=""/><meta name="generator" content="DocPad v6.78.4" />
    <meta name="viewport" content="width=device-width"/>
    <!-- - lato font-->
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,900,400italic" rel="stylesheet" type="text/css"/>
    <link href="https://fonts.googleapis.com/css?family=The+Girl+Next+Door" rel="stylesheet" type="text/css"/>
    <!--if lt IE 9
    script(async src="http://html5shim.googlecode.com/svn/trunk/html5.js")
    
    --><style >html.wait {
	cursor: wait !important;
	opacity: 0;
	transition: opacity 0.5s ease;
}</style><link  rel="stylesheet" href="/vendor/boilerplate.min.css" /><link  rel="stylesheet" href="/vendor/normalize.min.css" /><link  rel="stylesheet" href="/vendor/deck.js/deck.all.min.css" /><link  rel="stylesheet" href="/vendor/960_12_col_custom.min.css" /><link  rel="stylesheet" href="/styles/steve_deck_style.css" /><link  rel="stylesheet" href="/vendor/questionmark.js/question.mark.css" />
  </head>
  <body><script >(function(){
	/* Did we just livereload? */
var log = !!(localStorage && console && console.log && true);
if ( log && localStorage.getItem('/docpad-livereload/reloaded') === 'yes' ) {
	localStorage.removeItem('/docpad-livereload/reloaded');
	console.log('LiveReload completed at', new Date())
}

/* Listen for the regenerated event and perform a reload of the page when the event occurs */
var listen = function(){
	var primus = new Primus('/docpad-livereload');
	primus.on('data', function(data){
		if ( data && data.message ) {
			if ( data.message === 'generateBefore' ) {
				if ( log ) {
					console.log('LiveReload started at', new Date());
				}
				if ( typeof document.getElementsByTagName !== 'undefined' ) {
	document.getElementsByTagName('html')[0].className += ' wait';
}
			}
			else if ( data.message === 'generateAfter' ) {
				if ( log ) {
					localStorage.setItem('/docpad-livereload/reloaded', 'yes');
				}
				document.location.reload();
			}
		}
	});
};
	/* Inject socket into our page */
var inject = function(){
	var t = document.createElement('script');
	t.type = 'text/javascript';
	t.async = 'async';
	t.src = '/primus/primus.js';
	t.onload = listen;
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(t, s);
};
	if ( typeof Primus !== 'undefined' ) {
		listen();
	} else {
		inject();
	}
})();</script><script defer="defer"  src="/vendor/jquery.min.js"></script><script defer="defer"  src="/vendor/jquery-svgfix.js"></script><script defer="defer"  src="/vendor/jquery.crSplineBkg.js"></script><script defer="defer"  src="/vendor/velocity.min.js"></script><script defer="defer"  src="/vendor/marked.min.js"></script><script defer="defer"  src="/vendor/modernizr.custom.01932.js"></script><script defer="defer"  src="/vendor/deck.js/deck.velocity.js"></script><script defer="defer"  src="/vendor/deck.js/deck.all.min.js"></script><script defer="defer"  src="/vendor/jquery.jsPlumb-1.3.16-all-min.js"></script><script defer="defer"  src="/scripts/script.js"></script><script defer="defer"  src="/vendor/questionmark.js/question.mark.min.js"></script>
    <div id="helpUnderlay" class="help-underlay">
      <div id="helpModal" class="help-modal">
        <h1>Keyboard Shortcuts<kbd class="help-key"><span>?</span></kbd></h1>
        <div id="helpClose" class="help-close">×</div>
        <!-- .help-close-->
        <div id="helpModalContent" class="help-modal-content">
          <div id="helpListWrap" class="help-list-wrap">
            <ul class="help-list">
              <li class="help-key-unit"><kbd class="help-key"><span>→</span></kbd><span class="help-key-def">Next step</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>←</span></kbd><span class="help-key-def">Previous step</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>↓</span></kbd><span class="help-key-def">Skip this slide</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>↑</span></kbd><span class="help-key-def">Previous slide</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>m</span></kbd><span class="help-key-def">Show slide thumbnails</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>n</span></kbd><span class="help-key-def">Show notes</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>h</span></kbd><span class="help-key-def">Show handout latex source</span></li>
              <li class="help-key-unit"><kbd class="help-key"><span>N</span></kbd><span class="help-key-def">Show talk notes latex source</span></li>
            </ul>
            <!-- .help-list-->
          </div>
          <!-- .help-list-wrap-->
        </div>
        <!-- .help-modal-content-->
      </div>
      <!-- .help-modal-->
    </div>
    <!-- .help-underlay-->
    
    <div class="deck-notes">
      <div class="deck-notes-container"></div>
    </div>
    <div class="deck-handout">
      <div class="deck-handout-container"></div>
    </div>
    <div class="deck-container">
      <section id="instructions" class="slide">
        <div class="words">
          <div class="container_12">
            <div class="grid_12">
              <div class="middle">
                <p class="center">Click here and press the right key for the next slide (or swipe left)</p>
              </div>
            </div>
          </div>
        </div>
      </section>
      <section class="slide">
        <!-- .notes You won't believe how many people emailed me to say the slides don't work.-->
        <div class="words">
          <div class="container_12">
            <div class="grid_12">
              <p>also ...</p>
              <p>Press the left key to go backwards (or swipe right)</p>
              <p>Press n to toggle whether notes are shown (or add '?notes' to the url before the #)</p>
              <p>Press m or double tap to slide thumbnails (menu)</p>
              <p>Press ? at any time to show the keyboard shortcuts</p>
            </div>
          </div>
        </div>
      </section>
      <section id="objects_of_categorical_perception" class="slide">
        <div class="spacer">&nbsp;</div>
        <div style="" class="title-block">
          <div class="title-container">
            <h2 class="title1">The Objects of Categorical Perception</h2>
          </div>
        </div>
      </section>

<!-- param @cls and param @options should be objects-->




<section style="" class="slide">
  <div style="" class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">What are the perceptual processes supposed to categorise?</p>
          <div class="notes">standard view: fixed expressions linked to emotional categories</div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <p class="center"><img src="/img/aviezer_2012_fig2A3.jpg" style=""/>
  </p>
  <p class="source">Aviezer et al (2012, figure 2A3)</p>
  <div class="notes">But are the things categorised by perceptual processes facial configurations?
This view faces a problem.
There is evidence that
the same facial configuration can express intense joy or intense  anguish depending on the posture of the body it is attached to,
and, relatedly, that humans cannot accurately determine emotions from spontaneously occurring
(spontaneously occurring---i.e.\ as opposed to acted out)
facial configurations \citep{motley:1988_facial,aviezer:2008_angry,aviezer:2012_body}.
These and other findings, while not decisive, cast doubt on the view that categories of emotion are associated with categories of facial configurations \citep{hassin:2013_inherently}.
  </div>
  <div class="handout">The same facial configuration can express intense joy or intense anguish depending on the posture of
the body it is attached to; and humans cannot accurately determine emotions from
spontaneously occurring (as opposed to acted out) facial
configurations \citep{motley:1988_facial,aviezer:2008_angry,aviezer:2012_body}.
  </div>
</section>
<section style="" class="slide">
  <div style="" class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="notes handout show">Aviezer et al's puzzle:</p>
          <p class="notes handout ctd show"> <span>Given that  </span><span class="noblur">facial configurations</span><span> are not diagnostic of emotion, why  </span><span class="noblur">are they categorised by perceptual processes?</span></p>
          <div class="notes">This evidence makes the findings we have reviewed on categorical perception puzzling.
Given that the facial configurations are not diagnostic of emotion,
why are they categorised by perceptual processes?%
\footnote{
Compare \citet[p.\ 1228]{aviezer:2012_body}:
`although the faces are inherently ambiguous, viewers experience illusory affect and erroneously
report perceiving diagnostic affective valence in the face.'
}
This question appears unanswerable as long as we retain the assumption---for which, after all, no
argument was given---that the things categorical perception is supposed to categorise are facial
configurations.
          </div>
          <div class="slide">
            <p class="em-above">... maybe the aren’t.</p>
            <div class="notes">But if we reject this assumption, what is the alternative?
            </div>
          </div>
          <div class="slide">
            <div data-what="span:not(.noblur)" data-css="{&quot;blur&quot;:&quot;2px&quot;}" data-options="{&quot;duration&quot;:500}" class="dv dv-velocity"></div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section style="" class="slide">
  <div style="" class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p class="center">speech perception</p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="slide">
  <div style="z-index:-22;" class="right-half-white"></div>
  <div class="container_12">
    <div class="grid_6 words left-half">
      <div style="padding-right:1em;">
        <p class="center">articulation of phoneme</p>
      </div>
    </div>
    <div class="grid_6 words invert right-half">
      <div style="padding-left:1em;">
        <p class="center">expression of emotion</p>
      </div>
    </div>
    <div class="notes">Compare expressing an emotion by, say, smiling or frowning,  with articulating a phoneme.
    </div>
    <div class="clear"></div>
    <div class="slide">
      <div class="notes">Both have a communicative function (on expressions of emotion, see for example \citealp{blair:2003_facial,sato:2007_spontaneous})
and both are categorically perceived, 
but the phonetic case has been more extensively investigated.
      </div>
      <div class="grid_6 words left-half">
        <div style="padding-right:1em;">
          <p>- communicative function</p>
        </div>
      </div>
      <div class="grid_6 words invert right-half">
        <div style="padding-left:1em;">
          <p>- communicative function</p>
        </div>
      </div>
    </div>
    <div class="clear"></div>
    <div class="slide">
      <div class="notes">Variations due to coarticulation, rate of speech, dialect and many other factors mean that isolated acoustic signals are not generally diagnostic of phonemes:
in different contexts, the same acoustic signal might be a consequence of the articulation of any of several phonemes.
      </div>
      <div class="grid_6 words left-half">
        <div style="padding-right:1em;">
          <p>- isolated acoustic signals not diagnostic</p>
        </div>
      </div>
    </div>
    <div class="slide">
      <div class="notes">So here there is a parallel between speech and emotion.
Much as isolated facial expressions are not diagnostic of emotions (as we saw a moment ago), isolated acoustic signals are plausibly not diagnostic of phonetic articulations.
      </div>
      <div class="grid_6 words invert right-half">
        <div style="padding-left:1em;">
          <p>- isolated facial expressions not diagnostic</p>
        </div>
      </div>
    </div>
    <div class="clear"></div>
    <div class="slide">
      <div class="notes">Why then are isolated acoustic signals---which rarely even occur outside the lab---categorised by perceptual or motor processes at all?
To answer this question we first need a rough idea of what it is to articulate a phoneme.
Articulating a phoneme involves making coordinated movements of the lips, tongue, velum and larynx.
How these should move depends in complex ways on numerous factors including phonetic context \citep{Browman:1992da,Goldstein:2003bn}.
In preparing for such movements, it is plausible that the articulation of a particular phoneme is an outcome represented motorically,
where this motor representation coordinates the movements and normally does so in such a way as to increase the probability that the outcome represented will occur.
      </div>
      <div class="grid_6 words left-half">
        <div style="padding-right:1em;">
          <p>- complex coordinated<span class="goal-directed hide">, goal-directed </span><span> movements</span></p>
          <div class="slide">
            <div data-what=".goal-directed" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div>
            <div class="notes">This implies that the articulation of a particular phoneme,
although probably not an intentional action,
is a goal-directed action whose goal is the articulation of that phoneme.
            </div>
            <div class="notes">(On the link between  motor representation and goal-directed action, see \citealp{butterfill:2012_intention}.)
            </div>
            <div class="notes">Now some hold that the things categorised in categorical perception of speech are not sounds or movements (say) but rather these outcomes---the very outcomes in terms of which speech actions are represented motorically (\citealp{Liberman:2000gr}; see also \citealp{Browman:1992da}).%
\footnote{
Note that this claim does not entail commitment to other components of the motor theory of speech perception.
}
%
On this view, 
categorical perception of speech is a process which takes as input the bodily and acoustic effects of speech actions and attempts to identify which outcomes the actions are directed to bringing about, that is, which phonemes the speaker is attempting to articulate.
That isolated acoustic signals can engage this process and thereby trigger categorical perception  is merely a side-effect, albeit one with useful methodological consequences.
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="slide">
      <div class="grid_6 words invert right-half">
        <div style="padding-left:1em;">
          <p>- complex coordinated, goal-directed movements</p>
        </div>
      </div>
      <div class="notes">We can think of expressions of emotion as goal-directed in the same sense that 
articulations of phonemes are.
They are actions whose goal is the expression of a particular emotional episode.
      </div>
      <div class="notes">This may initially strike you as implausible given that such expressions of emotion can be spontaneous, unintentional and involuntary.
But note that expressing an emotion by, say, smiling or frowning,
whether intentionally or not,
involves making coordinated movements of multiple muscles
where exactly what should move and how can depend in complex ways on  contextual factors.
That such an expression of emotion is a goal-directed action follows just from its involving motor expertise
and being coordinated around an outcome (the goal) in virtue of that outcome being represented motorically.%
\footnote{
To increase the plausibility of the conjecture under consideration, we should allow that some categorically perceived expressions of emotion are not goal-directed actions but events grounded by two or more goal-directed actions.  
For ease of exposition I shall ignore this complication.
}
      </div>
      <div class="notes">Recognising that some expressions of emotion are goal-directed actions in this sense makes it possible to explain 
what distinguishes a genuine expression of emotion of this sort, a smile say, from something unexpressive like the exhalation of wind which might in principle resemble the smile kinematically. 
Like any goal-directed actions, genuine expressions of emotion of this sort are distinguished from 
their kinematically similar doppelgänger
in being directed to outcomes by virtue of the coordinating role of motor representations and processes.
      </div>
    </div>
    
  </div>
</section>
<section style="" class="slide">
  <div style="" class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <div class="notes">the wild conjecture under consideration is that the things categorical perception is supposed to categorise, the ‘expressions of emotion’, are actions of a certain type, and these are categorised by which outcomes they are directed to.
          </div>
          <p>What are the perceptual processes supposed to categorise?</p>
          <p class="em-above">Actions whose goals are to express certain emotions.</p>
          <div class="slide">
            <p class="indent">- The perceptual processes categorise events (not e.g. facial configurations).</p>
            <div class="notes">Let me explain the increasingly bold commitments involved in accepting this conjecture.
            </div>
            <div class="notes">First, the things categorised in categorical perception of expressions of emotion are events rather than configurations or anything static.
(Note that this is consistent the fact that static stimuli can trigger categorical perception; after all, static stimuli can also trigger motor representations of things like grasping \citep{borghi:2007_are}.)
            </div>
          </div>
          <div class="slide">
            <p class="indent">- These events are not mere physiological reactions.</p>
            <div class="notes">Second, these events are not mere physiological reactions (as we might intuitively take blushing to be) but things like frowning and smiling, whose performance involves motor expertise.
\footnote{
To emphasise, one consequence of this is that not everything which might intuitively be labelled as an expression of emotion is relevant to understanding what is categorised by perceptual processes.
%For example, in the right context a blush may signal emotion without requiring motor expertise.
}
            </div>
          </div>
          <div class="slide">
            <p class="indent">- These events are are perceptually categorised  by the outcomes to which they are directed.</p>
            <div class="notes">Third, these events are perceptually categorised  by the outcomes to which they are directed.
That is, outcomes represented motorically in performing these actions are things by which these events are categorised in categorical perception.
            </div>
            <div class="notes">Should we accept the wild conjecture? 
It goes well beyond the available evidence and currently lacks any reputable endorsement.
In fact, we lack direct evidence for even the first of the increasingly bold commitments just mentioned (namely, the claim that the things categorically perceived are events).
A further problem is that we know relatively little about the actions which, according to the wild conjecture, are the things categorical perception is supposed to categorise  (\citealp[p.\ 47]{scherer:2013_understanding}; see also \citealp{scherer:2007_are} and \citealp{fernandez-dols:2013_advances}).
However, 
the wild conjecture is less wild than the only published responses to the problems that motivate it.%
% (which, admittedly, are wilder than an acre of snakes).%
\footnote{
See
\citet[p.\ 15]{motley:1988_facial}: ‘particular emotions simply cannot be identified from psychophysiological responses’;
and
\citet[p.\ 289]{barrett:2011_context}: ‘scientists have created an artifact’.
}
And, as I shall now explain, several considerations make the wild conjecture seem at least worth testing.
            </div>
            <div class="notes">Consider again the procedure used in testing for categorical perception.
Each experiment begins with a system for categorising the stimuli (expressions).
This initial system  is either specified by the experimenters or, in some cases, by having the participants first divide stimuli into categories using verbal labels or occasionally using non-verbal decisions.
The experiment then seeks to measure whether this initial system of categories predicts patterns in discrimination.
But what determines  which category each stimulus is assigned to in  the initial system of categories?
You might guess that it is a matter of how likely people think it is that each stimulus---a particular facial configuration, say---would be associated with a particular emotion.
In fact this is wrong.
Instead, 
each stimulus is categorised in the initial system according to how suitable people think such an expression would be to express a given emotion: this is true whether the stimuli are facial \citep{horstmann:2002_facial} or vocal \citep{laukka:2011_exploring} expressions of emotion (see also \citealp[pp.\ 98--9]{parkinson:2013_contextualizing}).
To repeat, 
in explicitly assigning an expression to a category of emotion, people are not making a judgement about the probability of someone with that expression having that emotion:
they are making a judgement about which category of emotion the expression is most suited to expressing.
Why is this relevant to understanding what perceptual processes categorise?
The most straightforward way of interpreting the experiments on categorical perception is to suppose that they are testing whether perceptual processes categorise stimuli in the same ways as the initial system of categories does.
But we have just seen that the initial system categorises stimuli according to the emotions they would be best suited to expressing.
So on the most straightforward interpretation, 
the experiments on categorical perception of expressions of emotion 
are testing whether there are perceptual processes whose function is to categorise  actions of a certain type by the outcomes to which they are directed.
So the wild conjecture is needed for the most straightforward interpretation of these experiments.
This doesn't make it true but it does make it worth testing.
            </div>
            <div class="notes">So far I have focussed on evidence for categorical perception from experiments using faces as stimuli.
However, there is also evidence that perceptual processes categorise vocal and facial expressions alike (\citealp{grandjean:2005_voices,laukka:2005_categorical}; see also \citealp{jaywant:2012_categorical}).
We also know that 
%judgements about which emotion an observed person is expressing in a photograph can depend on the posture of the whole body and not only the face \citep{aviezer:2012_body}, and that 
various contextual factors can affect how even rapidly occurring perceptual processes discriminate expressions of emotion \citep{righart:2008_rapid}.
There is even indirect evidence that categorical perception may concern whole bodies rather than just faces or voices \citep{aviezer:2008_angry,aviezer:2011_automaticity}.
In short, categorical perception of expressions of emotion plausibly resembles categorical perception of speech in being a multimodal phenomenon which concerns the whole body and is affected by several types of contextual feature.
This is consistent with the wild conjecture we are considering.
The conjecture generates the further prediction that the effects of context on categorical perception of expressions of emotion will resemble the myriad effects of context on categorical perception of speech so that `every potential cue ... is an actual cue'
 (\citealp[p.\ 11]{Liberman:1985bn}; for evidence of context effects see in categorical perception of speech, for example, \citealp{Repp:1987xo}; \citealp{Nygaard:1995po} pp.\ 72--5; \citealp{Jusczyk:1997lz}, p.\ 44).
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section style="" class="slide">
  <div style="" class="container_12">
    <div class="grid_12 ">
      <div class="words">
        <div class="middle">
          <p>modest hypothesis about perceptual experience of emotion</p>
          <p class="em-above">Information about others’ emotions can faciliate categorical perception of their expressions of emotion,</p>
          <p>which gives rise to phenomenal expectations concerning their bodily configurations, articulations and movements.</p>
        </div>
      </div>
    </div>
  </div>
</section>
    </div>
  </body>
</html>