
<!-- - scripts.add(["/vendor/deck.js/deck.core.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.menu.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.hash.js"])--><!-- - scripts.add(["/vendor/deck.js/deck.notes.js"])--><html><head><!-- (c) copyright 2013 Stephen A. Butterfill--><meta charset="utf-8"/><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><title>Signature Limits | Philosophical Psychology</title><meta name="description" content="A signature limit of a model is a prediction which can be derived from the model,
which cannot be derived from any other models under consideration, and which is untrue.
Signature limits make it possible to test hypotheses about which model characterises
a particular mindreading process."/><meta name="keywords" content="philosophy, psychology, action, joint action, metarepresentation, perception"/><meta name="author" content=""/><meta name="generator" content="DocPad v6.78.4" /><meta name="viewport" content="width=device-width"/><!-- - lato font--><link href="https://fonts.googleapis.com/css?family=Lato:300,400,900,400italic" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=The+Girl+Next+Door" rel="stylesheet" type="text/css"/><!--if lt IE 9script(async src="http://html5shim.googlecode.com/svn/trunk/html5.js")
--><link  rel="stylesheet" href="/vendor/boilerplate.min.css" /><link  rel="stylesheet" href="/vendor/normalize.min.css" /><link  rel="stylesheet" href="/vendor/deck.js/deck.all.min.css" /><link  rel="stylesheet" href="/vendor/960_12_col_custom.min.css" /><link  rel="stylesheet" href="/styles/steve_deck_style.css" /><link  rel="stylesheet" href="/vendor/questionmark.js/question.mark.css" /></head><body><script defer="defer"  src="/vendor/jquery.min.js"></script><script defer="defer"  src="/vendor/jquery-svgfix.js"></script><script defer="defer"  src="/vendor/jquery.crSplineBkg.js"></script><script defer="defer"  src="/vendor/velocity.min.js"></script><script defer="defer"  src="/vendor/marked.min.js"></script><script defer="defer"  src="/vendor/modernizr.custom.01932.js"></script><script defer="defer"  src="/vendor/deck.js/deck.velocity.js"></script><script defer="defer"  src="/vendor/deck.js/deck.all.min.js"></script><script defer="defer"  src="/vendor/jquery.jsPlumb-1.3.16-all-min.js"></script><script defer="defer"  src="/scripts/script.js"></script><script defer="defer"  src="/vendor/questionmark.js/question.mark.min.js"></script><div id="helpUnderlay" class="help-underlay"><div id="helpModal" class="help-modal"><h1>Keyboard Shortcuts<kbd class="help-key"><span>?</span></kbd></h1><div id="helpClose" class="help-close">×</div><!-- .help-close--><div id="helpModalContent" class="help-modal-content"><div id="helpListWrap" class="help-list-wrap"><ul class="help-list"><li class="help-key-unit"><kbd class="help-key"><span>→</span></kbd><span class="help-key-def">Next step</span></li><li class="help-key-unit"><kbd class="help-key"><span>←</span></kbd><span class="help-key-def">Previous step</span></li><li class="help-key-unit"><kbd class="help-key"><span>↓</span></kbd><span class="help-key-def">Skip this slide</span></li><li class="help-key-unit"><kbd class="help-key"><span>↑</span></kbd><span class="help-key-def">Previous slide</span></li><li class="help-key-unit"><kbd class="help-key"><span>m</span></kbd><span class="help-key-def">Show slide thumbnails</span></li><li class="help-key-unit"><kbd class="help-key"><span>n</span></kbd><span class="help-key-def">Show notes</span></li><li class="help-key-unit"><kbd class="help-key"><span>h</span></kbd><span class="help-key-def">Show handout latex source</span></li><li class="help-key-unit"><kbd class="help-key"><span>N</span></kbd><span class="help-key-def">Show talk notes latex source</span></li></ul><!-- .help-list--></div><!-- .help-list-wrap--></div><!-- .help-modal-content--></div><!-- .help-modal--></div><!-- .help-underlay-->
<div class="deck-notes"><div class="deck-notes-container"></div></div><div class="deck-handout"><div class="deck-handout-container"></div></div><div class="deck-container"><section id="instructions" class="slide"><div class="words"><div class="container_12"><div class="grid_12"><div class="middle"><p class="center">Click here and press the right key for the next slide (or swipe left)</p></div></div></div></div></section><section class="slide"><!-- .notes You won't believe how many people emailed me to say the slides don't work.--><div class="words"><div class="container_12"><div class="grid_12"><p>also ...</p><p>Press the left key to go backwards (or swipe right)</p><p>Press n to toggle whether notes are shown (or add '?notes' to the url before the #)</p><p>Press m or double tap to slide thumbnails (menu)</p><p>Press ? at any time to show the keyboard shortcuts</p></div></div></div></section><section id="signature_limits" class="slide"><div class="spacer">&nbsp;</div><div style="" class="title-block"><div class="title-container"><h2 class="title1">Signature Limits</h2></div></div></section>
<!-- param @cls and param @options should be objects-->



<div class="handout">Automatic belief-tracking in adults and
belief-tracking in infants are both subject to signature limits
associated with minimal theory of mind
(\citealp{wang:2015_limits,Low:2012_identity,low:2014_quack,mozuraitis:2015_privileged};
contrast \citealp{scott:2015_infants}).</div><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="notes show"><p>How can we test </p><p>which model of the <span class="mental">mental </span><span> </span><span class="physical remove-me">physical </span></p><p><span> a process is using?</span></p></div><div class="slide"><p class="center em-above">Using signature limits!</p><div class="notes">[First say what signature limits in general are]</div><div class="notes"><As>I said,</As><a>signature limit of a model is a set of predictions derivable from the model which </a><are>incorrect, and which are not predictions of other models under consideration.</are></div></div></div></div></div></div></section><section class="slide"><div class="notes">Let me pause to spell out the logic of this.</div><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="center invert">signature limits</p></div></div></div><div class="right-half-white"></div><div class="container_12 notes show"><div class="grid_6 words left-half"><div style="padding-right:1em;"><div class="hypothesis"><p>Hypothesis 1</p><p class="indent"> <span class="response">Response R</span><span> is the product of a process using a model characterised by  </span><span class="theory1">Theory 1</span></p><div class="notes">These are the hypotheses I wanted to test.</div></div><div class="fact hide"><p class="em-above">Fact</p><p class="indent">Theory 1 predicts that the protagonist will J.</p></div><div class="prediction hide"><p class="em-above">Prediction of Hypothesis 1</p><p class="indent">Response R will proceed as if the protagonist will J.</p></div></div></div><div class="grid_6 words invert right-half"><div style="padding-left:1em;"><div class="hypothesis"><p>Hypothesis 2</p><p class="indent"> <span class="response">Response R</span><span> is the product of a process using a model characterised by </span><span class="theory2">Theory 2</span></p></div><div class="fact hide"><p class="em-above">Fact</p><p class="indent">Theory 2 predicts that the protagonist will not J.</p></div><div class="prediction hide"><p class="em-above">Prediction of Hypothesis 2</p><p class="indent">Response R will proceed as if the protagonist will not J</p></div></div></div><div class="slide"><div data-what=".theory1" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".theory1" data-cls="bkg-invert" class="dv dv-addclass"></div><div class="notes">E.g. minimal theory of mind.</div></div><div class="slide"><div data-what=".theory2" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".theory2" data-cls="bkg-invert" class="dv dv-addclass"></div><div class="notes">E.g. canonical theory of mind.</div></div><div class="slide"><div data-what=".response" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".response" data-cls="bkg-invert" class="dv dv-addclass"></div><div class="notes">The response might be an explicit verbal response, a proactive gaze, or anything else
that can indicate belief-tracking and its absence.</div></div><div class="slide"><div data-what=".theory2, .theory1" data-cls="bkg-invert" class="dv dv-removeclass"></div></div><div class="slide"><div data-what=".fact" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div><div class="notes">To test the hypotheses, I need to identify an area where the theories describing the models
make incompatible predictions.
This is a signature limit of impetus mechanics.</div></div><div class="slide"><div data-what=".prediction" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div><div class="notes">The fact allows me to derive different predicts from the hypotheses.</div></div></div></section><!-- [Cambridge slides 45--65] Signature limits; Prediction; Experiments --><section style="" class="slide"><img src="/img/unit_451/slide_cambridge_model_046.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><!-- *todo* remove first figure, replace with something more informative--><div class="handout">\begin{center}</div><div class="handout">\includegraphics[width=0.25\textwidth]{fig/signature_limits_table.png}</div><div class="handout">\end{center}</div><div class="handout">\begin{center}</div><div class="handout">  \includegraphics[width=0.3\textwidth]{fig/low_2012_fig.png}</div><div class="handout">\end{center} </div></div></div></div></section><section style="" class="slide"><img src="/img/unit_451/slide_cambridge_model_047.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/unit_451/slide_cambridge_model_048.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/unit_451/slide_cambridge_model_049.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="hem-around-children"><p>While the protagonist is present, the item is placed in Location-1.</p><p>The protagonist [ stays / leaves ], </p><p>and the item is <span class="step2 hide">[ </span><span>moved</span><span class="step2 hide"> / transformed ]</span><span>.</span></p><div class="slide"><div data-what=".step2" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div></div></div></div></div></div></div></section><section style="" class="slide"><img src="/img/low_watts2.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/low_watts3.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/low_watts4.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/low_watts5.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/low_watts1.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"></div></div></div></section><section style="" class="slide"><img src="/img/unit_451/slide_cambridge_model_061.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">drawn from Low & Watts (2013); Low et al (2014)</p><div class="notes">Here are standard anticipatory looking and looking time responses 
(Since they are approximately the same and this is rough, I'm only
giving you one bar for both measures)</div></div></div></div></section><section style="" class="slide"><img src="/img/unit_451/slide_cambridge_model_062.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">drawn from Low & Watts (2013); Low et al (2014)</p><div class="notes">Now look at what happens when we change the task to an identity/appearance task.</div></div></div></div></section><section style="" class="slide"><img src="/img/unit_451/slide_cambridge_model_063.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="source">drawn from Low & Watts (2013); Low et al (2014)</p><div class="notes">And this isn't because the subjects are confused: 
the switch from location to identity/appearance has no measurable effect
on explicit verbal responses.</div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><p>signature limits</p><div class="notes">[First say what signature limits in general are]</div><div class="notes"><As>I said,</As><a>signature limit of a model is a set of predictions derivable from the model which </a><are>incorrect, and which are not predictions of other models under consideration.</are></div><div class="notes">As the study just mentioned \citep{kozhevnikov:2001_impetus} beautifully illustrates, 
identifying signature limits can make it possible to test conjectures about which theory 
underpins a given cognitive phenomenon.</div><div class="slide"><p>of minimal models of mind</p><p class="indent">- identity as compression/expansion <span class="tested hide">[has been tested<span class="caveat">*</span><span>]</span></span></p><p class="indent">- duck/rabbit <span class="tested hide">[has been tested<span class="caveat">*</span><span>]</span></span></p><p class="indent">- fission/fusion <span class="tested hide">[is being tested<span class="caveat">*</span><span>]</span></span></p><p class="indent">- quantification </p></div><div class="slide"><div data-what=".tested" data-css="{&quot;opacity&quot;:1}" data-options="{&quot;visibility&quot;:&quot;visible&quot;,&quot;duration&quot;:400}" class="dv dv-velocity"></div></div><div class="slide"><div data-what=".caveat" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".caveat" data-cls="bkg-invert" class="dv dv-addclass"></div><div class="notes">There is a caveat.
I want to test the claim that automatic processes use minimal models of the mental.
When testing limits, people have used certain measures ...</div></div><div class="slide"><div class="notes show"></div><p class="em-above">measures:<p class="indent">- spontaneous anticipatory looking</p><p class="indent">- looking duration</p><p class="indent">- active helping (Fizke et al, 2017; unpublished data)</p></p><div class="notes">And now you can see the problem.
Which of these measures are driven by automatic processes?
Only for the second, looking duration, 
do we have evidence that it sometimes reflects processes that are
automatic in false belief tasks \citep{schneider:2014_task}.</div></div></div></div></div></section><section style="" class="slide"><img src="/img/fizke_unpublished_stimuli.jpg" width="1024px" style="" class="bkg"/><div style="" class="words"><div class="container_12"><div class="grid_12"><div class="notes">Just say that you can do this with other stimuli and paradigms, and we
have done this with infants and would like to do it with adults.</div><div class="notes">These findings complicate the picture: is helping driven by automatic processes only?
If not, why do we predict that the signature limit of minimal theory of mind
is found in this case too?</div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><p class="center"><div class="brightness-150"><div class="contrast-150"><img src="/img/scott_2015_fig2b.png" class="fill"/></div></div></p><p class="source">Scott et al (2015, figure 2b)</p><div class="notes">Scott and colleagues \citep{scott:2015_infants} provided other evidence 
suggesting that infants’ mindreading may be relatively sophisticated. 
Specifically, 17-month-olds watched a thief attempt to steal a preferred 
object (a rattling toy) when its owner was momentarily absent by substituting 
it with a less-preferred object (a non-rattling toy). Infants looked longer 
when the thief substituted the preferred object with a non-visually-matching 
silent toy compared to when the thief substituted it with a visually-matching 
silent toy. The authors postulated that infants can ascribe to the thief an 
intention to implant in the owner a false-belief about the identity of the 
substituted toy. The authors further suggested that infants make such ascriptions 
only when the substitution involves a visually-matching toy and the owner will 
not test whether the toy rattles on her return.</div><div class="notes">However, Scott et al.’s \citep{scott:2015_infants} explanations also 
require postulating that infants take the thief to be strikingly inept; 
despite having opportunity simply to pilfer from a closed box known to 
contain at least three rattling toys, the thief engages in elaborate 
deception which will be uncovered whenever the substituted toy is next 
shaken and the thief, as sole suspect, easily identified. A further 
difficulty is that factors unrelated to the thief’s mental states vary 
between conditions, such as the frequencies with which toys visually matching 
one present during the final phase of the test trial have rattled. These 
considerations jointly indicate that further evidence would be needed to 
support the claim that humans’ early mindreading capacity enables them to 
ascribe intentions concerning false beliefs involving numerical identity.</div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="notes">A note on the method again ...</div><div class="hem-around-children"><p class="center"> 1. a dual-process theory</p><p class="center"> motivates conjectures about</p><p class="center"> 2. a minimal model of minds and actions</p><p class="center"> which entails</p><p class="center"> 3. signature limits</p><p class="center"> that generate predictions.</p></div></div></div></div></div></section><section style="" class="slide"><div style="" class="words"><div class="container_12"><div class="grid_12"><div class="notes">A wish : an identity version of this van der Wel et al task which uses a paradigm optimal for
distinguishing automatic and non-automatic processes ...</div><img src="/img/van_der_wel_2014_fig1_phase1.png" style="margin-left:auto;margin-right:auto;display:block;"/><img src="/img/van_der_wel_2014_fig1_phase2.png" style="margin-left:auto;margin-right:auto;display:block;"/><img src="/img/van_der_wel_2014_fig1_phase3_TF.png" style="margin-left:auto;margin-right:auto;display:block;"/><img src="/img/van_der_wel_2014_fig1_phase4.png" style="margin-left:auto;margin-right:auto;display:block;"/><p class="source">van der Wel et al (2014, figure 1)</p><div class="notes">Prediction: when the process is automatic, the difference in curve will vanish 
when the task concerns a mistake about identity rather than location.</div><div class="notes">To make the task about identity, let the cube (say) transform into a
third shape, a diamond (say).  Then let the cylinder transform into a cube
and, let the diamond transform into a cylinder.
Let this happen when the protagonist is present (id-TB) or absent (id-FB).
This should not affect tracking the objects,
but it should affect tracking the protagonists' beliefs about the objects.
(Good controls are possible because can show the effect still 
occurs in location-FB vs location-TB with the transformations
(i.e. location-FB+id-TB vs location-TB+id-TB.))</div></div></div></div></section><section style="" class="slide"><div style="" class="container_12"><div class="grid_12 "><div class="words"><div class="middle"><div class="notes">We've just seen evidence for the second claim, as promised.</div><div class="notes show hem-around-children"><p>Constructing minimal theories of mind yields models of the mental which</p><p class="indent">... could be used by automatic mindreading processes.</p><p class="indent second-claim bkg-grey-row">... are used by some automatic mindreading processes.</p><p class="indent third-claim">... are the only models used by automatic mindreading processes.</p></div><div class="slide"><div data-what=".second-claim" data-cls="bkg-grey-row " class="dv dv-removeclass"></div><div data-what=".third-claim" data-cls="bkg-grey-row " class="dv dv-addclass"></div><div class="notes">The evidence we have doesn’t support the third claim (that minimal theories of mind
yield models which are are the only models used by automatic mindreading).</div></div><div class="slide"><div data-what=".third-claim" data-cls="bkg-grey-row " class="dv dv-removeclass"></div><div data-what=".third-claim" data-cls="bkg-red-row " class="dv dv-addclass"></div><div class="notes">I do think there's an interesting theoretical argument for the third claim but 
I'm not sure how interested people are so I've left that out.
(It's in an appendix.)</div></div><div class="slide second-part em-above"><p><span class="efficiency-required">Automaticity requires <span class="caveat">(some degree of)</span><span> cognitive efficiency,</span></span></p><p class="canonical-is-demanding">but using a canonical model is cognitively demanding.</p><div data-what=".caveat" data-cls="transition-04" class="dv dv-addclass"></div><div data-what=".caveat" data-cls="bkg-invert" class="dv dv-addclass"></div><div class="notes">[Move ahead to schneiders puzzle and then come back here.]</div><div data-what=".caveat" data-cls="bkg-invert" class="dv dv-removeclass"></div><div class="slide"><p class="indent">- working memory</p><p class="indent">- attention</p><p class="indent">- inhibitory control </p><div class="notes">[*todo: lots of references missing from the following, e.g. Quereshi et al;
good summary in Schniedier et al 2014 WHat do we know ... paper.]</div><div class="handout notes">For adults (and children who can do this),
representing perceptions and beliefs as such---and even merely holding in mind 
what another believes, where no inference is required---involves a measurable 
processing cost \citep{apperly:2008_back,apperly:2010_limits}, consumes attention 
and working memory in fully competent adults \citealp{Apperly:2009cc, 
lin:2010_reflexively, McKinnon:2007rr},  may require inhibition \citep{bull:2008_role} 
and makes demands on executive function \citep{apperly:2004_frontal,samson:2005_seeing}.</div><div class="notes">People sometimes argue that what is cognitively demanding has nothing to do with
belief ascription but extraneous demands imposed in these tasks.
But there is a wide range of evidence (listed on your handout) using different paradigms
and carefully controlling for just this possibility (for example, some studies
compare tasks that are about beliefs with tasks that are as similar as possible
but not about beliefs).</div><div class="notes">It makes sense to suppose that these cognitive demands are intrinsic rather than extraneous.
Compare representing beliefs in a canonical model with measuring temperature
using centigrade ...</div><div class="notes">Let me say one more thing about the cognitive demands of using a canonical model
of mental states for mindreading ...</div><div class="slide"><p class="indent">- <span class="bkg-pink">it makes people slow down</span></p></div><div class="notes">... it makes people slow down \citep{Wel:2013uq}.
(Also note that in \citet{lin:2010_reflexively}, even for people with high working 
memory capacity where no additional cognitive load is imposed, it takes significantly
longer to follow an instruction that requires visual perspective taking than
to follow an instruction that does not.)</div></div></div></div></div></div></div></section><div class="handout">Objection:
‘the theoretical arguments offered [...] are [...] unconvincing, and [...]
the data can be explained in other terms’
(\citealp{carruthers:2015_two}; see also \citealp{carruthers:2015_mindreading}).</div><div class="handout">‘A cooperative multi-system architecture is better able to explain infant belief representation than a
parallel architecture, and causal representation, schemas and models provide a more promising basis
for flexible belief representation than does a rule-based approach of the kind described by Butterfill
and Apperly’ (\citealp{christensen:_twoa}; see also \citealp{michael:2016_flexible,michael:2013_mindreading}).</div></div></body></html>